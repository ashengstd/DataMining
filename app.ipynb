{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引入必要库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入必要库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from model.vae_pipeline import train_vae\n",
    "from model.anomaly_detection_pipeline import train_vae_anomaly_detection\n",
    "\n",
    "# 选择设备\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_application_record = pd.read_csv(\"application_record.csv\")\n",
    "df_credit_record = pd.read_csv(\"credit_record.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 丢弃重复ID数据\n",
    "df_application_record = df_application_record.drop_duplicates(subset = 'ID', keep = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调整数据框，以便仅使用一致的ID进行处理\n",
    "df_application_record = df_application_record[df_application_record['ID'].isin(df_credit_record['ID'])]\n",
    "df_credit_record = df_credit_record[df_credit_record['ID'].isin(df_application_record['ID'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成标签用于柱状图\n",
    "label_dict = {'1': 0, '2': 0, '3': 0, '4': 0, '5': 0, 'X': -1, 'C': 1, '0': 1}\n",
    "df_credit_record['APPROVED'] = df_credit_record['STATUS'].map(label_dict)\n",
    "df_credit_record = df_credit_record[df_credit_record['APPROVED'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并数据\n",
    "df_application_record = df_application_record.merge(df_credit_record, on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_application_record = df_application_record[df_application_record['MONTHS_BALANCE']==-4]\n",
    "df_application_record.loc[df_application_record[\"NAME_INCOME_TYPE\"]==\"Pensioner\",\"OCCUPATION_TYPE\"] = \"Pension\"\n",
    "df_application_record.loc[df_application_record[\"NAME_INCOME_TYPE\"]==\"Commercial associate\",\"OCCUPATION_TYPE\"] = \"Commercial associate\"\n",
    "df_application_record.loc[df_application_record[\"NAME_INCOME_TYPE\"]==\"State servant\",\"OCCUPATION_TYPE\"] = \"State servant\"\n",
    "df_application_record.loc[df_application_record[\"NAME_INCOME_TYPE\"]==\"Student\",\"OCCUPATION_TYPE\"] = \"Student\"\n",
    "df_application_record = df_application_record.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_application_record['Work_Time'] = -(df_application_record['DAYS_EMPLOYED'])//365\n",
    "\n",
    "df_application_record = df_application_record.drop(df_application_record[df_application_record['Work_Time']>50].index)\n",
    "df_application_record = df_application_record.drop(df_application_record[df_application_record['Work_Time']<0].index)\n",
    "df_application_record = df_application_record.drop(columns=['STATUS'])\n",
    "df_application_record.drop(['DAYS_EMPLOYED'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_date = pd.to_datetime('2023-01-01')\n",
    "df_application_record['BIRTH_DATE'] = baseline_date + pd.to_timedelta(df_application_record['DAYS_BIRTH'], unit='D')\n",
    "df_application_record['AGE'] = (baseline_date - df_application_record['BIRTH_DATE']).dt.days // 365\n",
    "df_application_record = df_application_record.drop(columns=['DAYS_BIRTH','BIRTH_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = False\n",
    "if onehot:\n",
    "    categorical_columns = ['CODE_GENDER', 'NAME_FAMILY_STATUS', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']\n",
    "    dummy_columns = ['NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE']\n",
    "else:\n",
    "    categorical_columns = ['CODE_GENDER', 'NAME_FAMILY_STATUS', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE']\n",
    "    dummy_columns = []\n",
    "categorical_df = df_application_record[categorical_columns]\n",
    "categorical_df = categorical_df.apply(lambda x: pd.factorize(x)[0])\n",
    "categorical_df = pd.DataFrame(categorical_df)\n",
    "df_application_record[categorical_columns] = categorical_df\n",
    "df_application_record = pd.get_dummies(df_application_record, columns=dummy_columns)\n",
    "df_application_record.to_csv('dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# df_application_record['AMT_INCOME_TOTAL']=scaler.fit_transform(df_application_record['AMT_INCOME_TOTAL'].values.reshape(-1, 1))\n",
    "# df_application_record['DAYS_EMPLOYED']=scaler.fit_transform(df_application_record['DAYS_EMPLOYED'].values.reshape(-1, 1))\n",
    "# df_application_record['MONTHS_BALANCE']=scaler.fit_transform(df_application_record['MONTHS_BALANCE'].values.reshape(-1, 1))\n",
    "# scaler = StandardScaler()\n",
    "# df_application_record['CNT_FAM_MEMBERS']=scaler.fit_transform(df_application_record['CNT_FAM_MEMBERS'].values.reshape(-1, 1))\n",
    "# df_application_record['AGE']=scaler.fit_transform(df_application_record['AGE'].values.reshape(-1, 1))\n",
    "\n",
    "negative_data_orgin = df_application_record[df_application_record['APPROVED']==0]\n",
    "negative_data = negative_data_orgin.drop(['APPROVED', 'ID','CODE_GENDER'], axis = 1)\n",
    "\n",
    "X = df_application_record.drop(['APPROVED', 'ID','CODE_GENDER'], axis = 1)\n",
    "y = df_application_record['APPROVED']\n",
    "X = np.array(X,dtype=float)\n",
    "y = np.array(y, dtype=int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "scalar = StandardScaler()\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_test = scalar.fit_transform(X_test)\n",
    "\n",
    "negative_data = scalar.fit_transform(np.array(negative_data,dtype=float))\n",
    "negative_label_list = np.zeros(len(negative_data))\n",
    "\n",
    "\n",
    "# 创建 RandomUnderSampler 对象\n",
    "undersampler = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "# 使用 RandomUnderSampler 来生成平衡的训练集\n",
    "X_train_under_random, y_train_under_random = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# 创建RandomOverSampler对象\n",
    "oversampler = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "# 使用RandomOverSampler来生成平衡的训练集\n",
    "X_train_over_random, y_train_over_random = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# 创建TomekLinks对象\n",
    "undersampler = TomekLinks()\n",
    "\n",
    "# 使用TomekLinks来生成平衡的训练集\n",
    "X_train_under_tomelinks, y_train_under_tomelinks = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# 创建SMOTE对象\n",
    "smote = SMOTE(sampling_strategy='minority',random_state=42)\n",
    "\n",
    "# 使用SMOTE来生成平衡的训练集\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [\n",
    "             (X_train, y_train, \"Original Data\"),\n",
    "             (X_train_over_random,y_train_over_random, \"Over-sampled Data\"),\n",
    "             (X_train_under_random,y_train_under_random, \"Under-sampled Data\"),\n",
    "             (X_train_under_tomelinks,y_train_under_tomelinks, \"Tomelinks Data\"),\n",
    "             (X_train_smote,y_train_smote, \"SMOTE Data\")\n",
    "            ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_data= []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': 0.05,\n",
    "    'reg_lambda': 1.,\n",
    "    'reg_alpha': .1,\n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 100,\n",
    "    'colsample_bytree': .5,\n",
    "    'min_child_samples': 100,\n",
    "    'subsample': .9,\n",
    "    'importance_type': 'gain',\n",
    "    'random_state': 71,\n",
    "    'num_leaves': 32,\n",
    "    'force_col_wise': True,\n",
    "    'scale_pos_weight': 1,\n",
    "    'bagging_freq': 5,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        86\n",
      "           1       0.98      1.00      0.99      3663\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.49      3749\n",
      "weighted avg       0.95      0.98      0.97      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00     300.0\n",
      "         1.0       0.00      1.00      0.00       0.0\n",
      "\n",
      "    accuracy                           1.00     300.0\n",
      "   macro avg       0.50      0.50      0.00     300.0\n",
      "weighted avg       1.00      0.00      0.00     300.0\n",
      "\n",
      "300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.24      0.05        86\n",
      "           1       0.98      0.82      0.89      3663\n",
      "\n",
      "    accuracy                           0.81      3749\n",
      "   macro avg       0.50      0.53      0.47      3749\n",
      "weighted avg       0.96      0.81      0.87      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.44      0.61       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.44       300\n",
      "   macro avg       0.50      0.72      0.31       300\n",
      "weighted avg       1.00      0.44      0.61       300\n",
      "\n",
      "300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.57      0.05        86\n",
      "           1       0.98      0.52      0.68      3663\n",
      "\n",
      "    accuracy                           0.52      3749\n",
      "   macro avg       0.50      0.54      0.36      3749\n",
      "weighted avg       0.96      0.52      0.66      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.51      0.68       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.51       300\n",
      "   macro avg       0.50      0.76      0.34       300\n",
      "weighted avg       1.00      0.51      0.68       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        86\n",
      "           1       0.98      1.00      0.99      3663\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.49      3749\n",
      "weighted avg       0.95      0.98      0.97      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00     300.0\n",
      "         1.0       0.00      1.00      0.00       0.0\n",
      "\n",
      "    accuracy                           1.00     300.0\n",
      "   macro avg       0.50      0.50      0.00     300.0\n",
      "weighted avg       1.00      0.00      0.00     300.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.99      0.04        86\n",
      "           1       0.97      0.01      0.02      3663\n",
      "\n",
      "    accuracy                           0.03      3749\n",
      "   macro avg       0.50      0.50      0.03      3749\n",
      "weighted avg       0.95      0.03      0.02      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "performance_data = []\n",
    "for X_train_processed, y_train_processed, method_name in data_list:\n",
    "    lgb_model = lgb.LGBMClassifier(**params, verbose=-1)\n",
    "\n",
    "    lgb_model.fit(X_train_processed, y_train_processed)\n",
    "\n",
    "    print(len(negative_data))\n",
    "    y_pred = lgb_model.predict(X_test)\n",
    "    y_prob = lgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    negative_data_pred = lgb_model.predict(negative_data)\n",
    "    negative_accuracy = accuracy_score(negative_label_list, negative_data_pred)\n",
    "\n",
    "    print(\n",
    "        classification_report(negative_label_list,\n",
    "                              negative_data_pred,\n",
    "                              zero_division=1))\n",
    "\n",
    "    performance_data.append({\n",
    "        'Classification Method' : 'LightGBM',\n",
    "        'Data Process Method': method_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Negative Accuracy': negative_accuracy,\n",
    "    })\n",
    "    index += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Original Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.03      0.06        86\n",
      "           1       0.98      0.99      0.99      3663\n",
      "\n",
      "    accuracy                           0.97      3749\n",
      "   macro avg       0.55      0.51      0.52      3749\n",
      "weighted avg       0.96      0.97      0.96      3749\n",
      "\n",
      "Classification Report for Original Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.01      0.01       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.01       300\n",
      "   macro avg       0.50      0.50      0.01       300\n",
      "weighted avg       1.00      0.01      0.01       300\n",
      "\n",
      "Classification Report for Over-sampled Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.15      0.12        86\n",
      "           1       0.98      0.97      0.97      3663\n",
      "\n",
      "    accuracy                           0.95      3749\n",
      "   macro avg       0.54      0.56      0.55      3749\n",
      "weighted avg       0.96      0.95      0.95      3749\n",
      "\n",
      "Classification Report for Over-sampled Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.14      0.24       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.14       300\n",
      "   macro avg       0.50      0.57      0.12       300\n",
      "weighted avg       1.00      0.14      0.24       300\n",
      "\n",
      "Classification Report for Under-sampled Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.60      0.05        86\n",
      "           1       0.98      0.52      0.68      3663\n",
      "\n",
      "    accuracy                           0.52      3749\n",
      "   macro avg       0.51      0.56      0.37      3749\n",
      "weighted avg       0.96      0.52      0.67      3749\n",
      "\n",
      "Classification Report for Under-sampled Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.79      0.88       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.79       300\n",
      "   macro avg       0.50      0.90      0.44       300\n",
      "weighted avg       1.00      0.79      0.88       300\n",
      "\n",
      "Classification Report for Tomelinks Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.03      0.06        86\n",
      "           1       0.98      0.99      0.99      3663\n",
      "\n",
      "    accuracy                           0.97      3749\n",
      "   macro avg       0.55      0.51      0.52      3749\n",
      "weighted avg       0.96      0.97      0.96      3749\n",
      "\n",
      "Classification Report for Tomelinks Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.01      0.01       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.01       300\n",
      "   macro avg       0.50      0.50      0.01       300\n",
      "weighted avg       1.00      0.01      0.01       300\n",
      "\n",
      "Classification Report for SMOTE Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.93      0.05        86\n",
      "           1       0.99      0.14      0.25      3663\n",
      "\n",
      "    accuracy                           0.16      3749\n",
      "   macro avg       0.51      0.54      0.15      3749\n",
      "weighted avg       0.97      0.16      0.24      3749\n",
      "\n",
      "Classification Report for SMOTE Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       0.50      1.00      0.50       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for X_train_processed, y_train_processed, method_name in data_list:\n",
    "    rfc = RandomForestClassifier(n_estimators=1000, max_features=12)\n",
    "    rfc.fit(X_train_processed, y_train_processed)\n",
    "    predictions = rfc.predict(X_test)\n",
    "    print(f\"Classification Report for {method_name} on Test Data:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    negative_predictions = rfc.predict(negative_data)\n",
    "    print(f\"Classification Report for {method_name} on Negative Data:\")\n",
    "    print(\n",
    "        classification_report(negative_label_list,\n",
    "                              negative_predictions,\n",
    "                              zero_division=1))\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    performance_data.append({\n",
    "        'Classification Method': 'Random Forest',\n",
    "        'Data Process Method': method_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Negative Accuracy': negative_accuracy,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost for Desicion Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Original Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        86\n",
      "           1       0.98      1.00      0.99      3663\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.49      3749\n",
      "weighted avg       0.95      0.98      0.97      3749\n",
      "\n",
      "Classification Report for Original Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00     300.0\n",
      "         1.0       0.00      1.00      0.00       0.0\n",
      "\n",
      "    accuracy                           1.00     300.0\n",
      "   macro avg       0.50      0.50      0.00     300.0\n",
      "weighted avg       1.00      0.00      0.00     300.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Over-sampled Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.38      0.05        86\n",
      "           1       0.98      0.66      0.79      3663\n",
      "\n",
      "    accuracy                           0.65      3749\n",
      "   macro avg       0.50      0.52      0.42      3749\n",
      "weighted avg       0.96      0.65      0.77      3749\n",
      "\n",
      "Classification Report for Over-sampled Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.40      0.57       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.40       300\n",
      "   macro avg       0.50      0.70      0.29       300\n",
      "weighted avg       1.00      0.40      0.57       300\n",
      "\n",
      "Classification Report for Under-sampled Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.55      0.05        86\n",
      "           1       0.98      0.54      0.69      3663\n",
      "\n",
      "    accuracy                           0.54      3749\n",
      "   macro avg       0.50      0.54      0.37      3749\n",
      "weighted avg       0.96      0.54      0.68      3749\n",
      "\n",
      "Classification Report for Under-sampled Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.52      0.69       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.52       300\n",
      "   macro avg       0.50      0.76      0.34       300\n",
      "weighted avg       1.00      0.52      0.69       300\n",
      "\n",
      "Classification Report for Tomelinks Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        86\n",
      "           1       0.98      1.00      0.99      3663\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.49      3749\n",
      "weighted avg       0.95      0.98      0.97      3749\n",
      "\n",
      "Classification Report for Tomelinks Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00     300.0\n",
      "         1.0       0.00      1.00      0.00       0.0\n",
      "\n",
      "    accuracy                           1.00     300.0\n",
      "   macro avg       0.50      0.50      0.00     300.0\n",
      "weighted avg       1.00      0.00      0.00     300.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for SMOTE Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      1.00      0.04        86\n",
      "           1       1.00      0.00      0.00      3663\n",
      "\n",
      "    accuracy                           0.02      3749\n",
      "   macro avg       0.51      0.50      0.02      3749\n",
      "weighted avg       0.98      0.02      0.00      3749\n",
      "\n",
      "Classification Report for SMOTE Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for X_train_processed, y_train_processed, method_name in data_list:\n",
    "    # 使用决策树桩作为弱分类器，也可以选择其他弱分类器\n",
    "    base_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "    # 使用AdaBoost分类器\n",
    "    adaboost = AdaBoostClassifier(base_classifier,\n",
    "                                  n_estimators=1000,\n",
    "                                  algorithm='SAMME',\n",
    "                                  random_state=42)\n",
    "\n",
    "    # 训练模型\n",
    "    adaboost.fit(X_train_processed, y_train_processed)\n",
    "\n",
    "    # 在测试集上进行预测和评估\n",
    "    predictions_test = adaboost.predict(X_test)\n",
    "    print(f\"Classification Report for {method_name} on Test Data:\")\n",
    "    print(classification_report(y_test, predictions_test))\n",
    "\n",
    "    # 在负样本数据上进行预测和评估\n",
    "    predictions_negative = adaboost.predict(negative_data)\n",
    "    print(f\"Classification Report for {method_name} on Negative Data:\")\n",
    "    print(\n",
    "        classification_report(negative_label_list,\n",
    "                              predictions_negative,\n",
    "                              zero_division=1))\n",
    "    accuracy = accuracy_score(y_test, predictions_test)\n",
    "    precision = precision_score(y_test, predictions_test)\n",
    "    recall = recall_score(y_test, predictions_test)\n",
    "    f1 = f1_score(y_test, predictions_test)\n",
    "    performance_data.append({\n",
    "        'Classification Method': 'AdaBoost for Decision Tree',\n",
    "        'Data Process Method': method_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Negative Accuracy': negative_accuracy,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Original Data - SVM Classification Report on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        86\n",
      "           1       0.98      1.00      0.99      3663\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.49      3749\n",
      "weighted avg       0.95      0.98      0.97      3749\n",
      "\n",
      "Method: Original Data - SVM Classification Report on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Over-sampled Data - SVM Classification Report on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.26      0.06        86\n",
      "           1       0.98      0.82      0.89      3663\n",
      "\n",
      "    accuracy                           0.81      3749\n",
      "   macro avg       0.51      0.54      0.48      3749\n",
      "weighted avg       0.96      0.81      0.88      3749\n",
      "\n",
      "Method: Over-sampled Data - SVM Classification Report on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "Method: Under-sampled Data - SVM Classification Report on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.59      0.05        86\n",
      "           1       0.98      0.52      0.68      3663\n",
      "\n",
      "    accuracy                           0.52      3749\n",
      "   macro avg       0.51      0.56      0.37      3749\n",
      "weighted avg       0.96      0.52      0.67      3749\n",
      "\n",
      "Method: Under-sampled Data - SVM Classification Report on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "Method: Tomelinks Data - SVM Classification Report on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        86\n",
      "           1       0.98      1.00      0.99      3663\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.49      3749\n",
      "weighted avg       0.95      0.98      0.97      3749\n",
      "\n",
      "Method: Tomelinks Data - SVM Classification Report on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: SMOTE Data - SVM Classification Report on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.20      0.06        86\n",
      "           1       0.98      0.86      0.92      3663\n",
      "\n",
      "    accuracy                           0.84      3749\n",
      "   macro avg       0.51      0.53      0.49      3749\n",
      "weighted avg       0.96      0.84      0.90      3749\n",
      "\n",
      "Method: SMOTE Data - SVM Classification Report on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for X_train_processed, y_train_processed, method_name in data_list:\n",
    "   # 使用 SVM 替代 RandomForestClassifier\n",
    "   svm_model = SVC()\n",
    "   svm_model.fit(X_train_processed, y_train_processed)\n",
    "\n",
    "   # SVM 在测试集上的分类报告\n",
    "   predictions_svm_test = svm_model.predict(X_test)\n",
    "   print(f\"Method: {method_name} - SVM Classification Report on Test Data:\")\n",
    "   print(classification_report(y_test, predictions_svm_test))\n",
    "\n",
    "   # SVM 在负样本上的分类报告\n",
    "   predictions_svm_negative = svm_model.predict(negative_data)\n",
    "   print(\n",
    "      f\"Method: {method_name} - SVM Classification Report on Negative Data:\")\n",
    "   print(\n",
    "      classification_report(negative_label_list,\n",
    "                           predictions_negative,\n",
    "                           zero_division=1))\n",
    "   accuracy = accuracy_score(y_test, predictions_svm_test)\n",
    "   precision = precision_score(y_test, predictions_svm_test)\n",
    "   recall = recall_score(y_test, predictions_svm_test)\n",
    "   f1 = f1_score(y_test, predictions_svm_test)\n",
    "   performance_data.append({\n",
    "       'Classification Method': 'SVM',\n",
    "       'Data Process Method': method_name,\n",
    "       'Accuracy': accuracy,\n",
    "       'Precision': precision,\n",
    "       'Recall': recall,\n",
    "       'F1 Score': f1,\n",
    "       'Negative Accuracy': negative_accuracy,\n",
    "   })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# for X_train_processed, y_train_processed, method_name in data_list:\n",
    "#     # 使用支持向量机作为弱分类器\n",
    "#     base_classifier = SVC(kernel='linear', C=1.0)\n",
    "\n",
    "#     # 使用AdaBoost分类器\n",
    "#     adaboost = AdaBoostClassifier(base_classifier,\n",
    "#                                   n_estimators=1000,\n",
    "#                                   algorithm='SAMME',\n",
    "#                                   random_state=42)\n",
    "\n",
    "#     # 训练模型\n",
    "#     adaboost.fit(X_train_processed, y_train_processed)\n",
    "\n",
    "#     # 在测试集上进行预测和评估\n",
    "#     predictions_test = adaboost.predict(X_test)\n",
    "#     print(f\"Classification Report for {method_name} on Test Data:\")\n",
    "#     print(classification_report(y_test, predictions_test))\n",
    "\n",
    "#     # 在负样本数据上进行预测和评估\n",
    "#     predictions_negative = adaboost.predict(negative_data)\n",
    "#     print(f\"Classification Report for {method_name} on Negative Data:\")\n",
    "#     print(\n",
    "#         classification_report(negative_label_list,\n",
    "#                               predictions_negative,\n",
    "#                               zero_division=1))\n",
    "#     accuracy = accuracy_score(y_test, predictions_test)\n",
    "#     precision = precision_score(y_test, predictions_test)\n",
    "#     recall = recall_score(y_test, predictions_test)\n",
    "#     f1 = f1_score(y_test, predictions_test)\n",
    "#     performance_data.append({\n",
    "#         'Classification Method': 'AdaBoost for SVM',\n",
    "#         'Data Process Method': method_name,\n",
    "#         'Accuracy': accuracy,\n",
    "#         'Precision': precision,\n",
    "#         'Recall': recall,\n",
    "#         'F1 Score': f1,\n",
    "#         'Negative Accuracy': negative_accuracy,\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 0\n",
    "# for X_train_processed, y_train_processed, method_name in data_list:\n",
    "#     svm_model = SVC()\n",
    "#     train_feature = train_features[index]\n",
    "#     test_feature = test_features[index]\n",
    "#     svm_model.fit(train_feature, y_train_processed)\n",
    "#     predictions = svm_model.predict(test_feature)\n",
    "#     print(classification_report(y_test,predictions))\n",
    "#     predictions = svm_model.predict(negative_data_list[index])\n",
    "#    print(classification_report(negative_label_list, predictions_negative, zero_division=1))\n",
    "#     index = index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for the method: Original Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 249\n",
      "Training for the method: Over-sampled Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 249\n",
      "Training for the method: Under-sampled Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 249\n",
      "Training for the method: Tomelinks Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 249\n",
      "Training for the method: SMOTE Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 249\n"
     ]
    }
   ],
   "source": [
    "model_list = []\n",
    "for X_train_processed, _, method_name in data_list:\n",
    "   print(\"Training for the method: \" + method_name)\n",
    "   model = train_vae(X_train=X_train_processed,X_test=X_test, progress=False,num_epoch=250).eval()\n",
    "   model_list.append(model)\n",
    "\n",
    "total_list = [ t+ (data,)  for t, data in zip(data_list, model_list)]\n",
    "\n",
    "index = 0\n",
    "train_features = []\n",
    "test_features = []\n",
    "negative_data_list = []\n",
    "for X_train_processed, _, method_name, __ in total_list:\n",
    "    train_features.append(model_list[index].encoder(torch.Tensor(X_train_processed).to(device)).cpu().detach().numpy())\n",
    "    test_features.append(model_list[index].encoder(torch.Tensor(X_test).to(device)).detach().cpu().numpy())\n",
    "    negative_data_list.append(model_list[index].encoder(torch.Tensor(negative_data).to(device)).detach().cpu().numpy())\n",
    "    index+=1\n",
    "\n",
    "   \n",
    "# for X_train_processed, _, method_name, model in model_list:\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         encoded_data = model.encoder(torch.Tensor(X_train_processed).to(device))\n",
    "#         encoded_data = encoded_data.cpu().numpy()\n",
    "#         tsne = TSNE(n_components=2)\n",
    "#         reduced_data = tsne.fit_transform(encoded_data)\n",
    "\n",
    "# plt.scatter(reduced_data[:, 0], reduced_data[:, 1])\n",
    "# plt.title(\"VAE Visualization\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM for VAE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        86\n",
      "           1       0.98      1.00      0.99      3663\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.49      3749\n",
      "weighted avg       0.95      0.98      0.97      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00     300.0\n",
      "         1.0       0.00      1.00      0.00       0.0\n",
      "\n",
      "    accuracy                           1.00     300.0\n",
      "   macro avg       0.50      0.50      0.00     300.0\n",
      "weighted avg       1.00      0.00      0.00     300.0\n",
      "\n",
      "300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.26      0.05        86\n",
      "           1       0.98      0.81      0.89      3663\n",
      "\n",
      "    accuracy                           0.80      3749\n",
      "   macro avg       0.50      0.53      0.47      3749\n",
      "weighted avg       0.96      0.80      0.87      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.34      0.50       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.34       300\n",
      "   macro avg       0.50      0.67      0.25       300\n",
      "weighted avg       1.00      0.34      0.50       300\n",
      "\n",
      "300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.64      0.05        86\n",
      "           1       0.98      0.48      0.64      3663\n",
      "\n",
      "    accuracy                           0.48      3749\n",
      "   macro avg       0.51      0.56      0.35      3749\n",
      "weighted avg       0.96      0.48      0.63      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.57      0.72       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.57       300\n",
      "   macro avg       0.50      0.78      0.36       300\n",
      "weighted avg       1.00      0.57      0.72       300\n",
      "\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        86\n",
      "           1       0.98      1.00      0.99      3663\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.49      3749\n",
      "weighted avg       0.95      0.98      0.97      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00     300.0\n",
      "         1.0       0.00      1.00      0.00       0.0\n",
      "\n",
      "    accuracy                           1.00     300.0\n",
      "   macro avg       0.50      0.50      0.00     300.0\n",
      "weighted avg       1.00      0.00      0.00     300.0\n",
      "\n",
      "300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.38      0.05        86\n",
      "           1       0.98      0.64      0.77      3663\n",
      "\n",
      "    accuracy                           0.64      3749\n",
      "   macro avg       0.50      0.51      0.41      3749\n",
      "weighted avg       0.96      0.64      0.76      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.62      0.76       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.62       300\n",
      "   macro avg       0.50      0.81      0.38       300\n",
      "weighted avg       1.00      0.62      0.76       300\n",
      "\n",
      "   Classification Method Data Process Method  Accuracy  Precision    Recall  \\\n",
      "0  LightGBM for VAE data       Original Data  0.977061   0.977061  1.000000   \n",
      "1  LightGBM for VAE data   Over-sampled Data  0.795145   0.978829  0.807808   \n",
      "2  LightGBM for VAE data  Under-sampled Data  0.483062   0.982652  0.479388   \n",
      "3  LightGBM for VAE data      Tomelinks Data  0.977061   0.977061  1.000000   \n",
      "4  LightGBM for VAE data          SMOTE Data  0.635103   0.977926  0.641005   \n",
      "\n",
      "   F1 Score  Negative Accuracy  \n",
      "0  0.988397           0.000000  \n",
      "1  0.885133           0.336667  \n",
      "2  0.644404           0.566667  \n",
      "3  0.988397           0.000000  \n",
      "4  0.774406           0.616667  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "performance_data = []\n",
    "data_df = pd.DataFrame(columns=['Method', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Negative Accuracy'])\n",
    "\n",
    "for X_train_processed, y_train_processed, method_name, _ in total_list:\n",
    "    lgb_model = lgb.LGBMClassifier(**params, verbose=-1)\n",
    "\n",
    "    lgb_model.fit(train_features[index], y_train_processed)\n",
    "\n",
    "    print(len(negative_data))\n",
    "    y_pred = lgb_model.predict(test_features[index])\n",
    "    y_prob = lgb_model.predict_proba(test_features[index])[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    negative_data_pred = lgb_model.predict(negative_data_list[index])\n",
    "    negative_accuracy = accuracy_score(negative_label_list, negative_data_pred)\n",
    "\n",
    "    print(\n",
    "        classification_report(negative_label_list,\n",
    "                              negative_data_pred,\n",
    "                              zero_division=1))\n",
    "\n",
    "    performance_data.append({\n",
    "        'Classification Method': 'LightGBM for VAE data',\n",
    "        'Data Process Method': method_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Negative Accuracy': negative_accuracy,\n",
    "    })\n",
    "    index += 1\n",
    "\n",
    "data_df = pd.DataFrame(performance_data)\n",
    "print(data_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM for VAE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        86\n",
      "           1       0.98      1.00      0.99      3663\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.49      3749\n",
      "weighted avg       0.95      0.98      0.97      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00     300.0\n",
      "         1.0       0.00      1.00      0.00       0.0\n",
      "\n",
      "    accuracy                           1.00     300.0\n",
      "   macro avg       0.50      0.50      0.00     300.0\n",
      "weighted avg       1.00      0.00      0.00     300.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.36      0.07        86\n",
      "           1       0.98      0.78      0.87      3663\n",
      "\n",
      "    accuracy                           0.77      3749\n",
      "   macro avg       0.51      0.57      0.47      3749\n",
      "weighted avg       0.96      0.77      0.85      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.55      0.71       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.55       300\n",
      "   macro avg       0.50      0.77      0.35       300\n",
      "weighted avg       1.00      0.55      0.71       300\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.57      0.05        86\n",
      "           1       0.98      0.48      0.65      3663\n",
      "\n",
      "    accuracy                           0.48      3749\n",
      "   macro avg       0.50      0.53      0.35      3749\n",
      "weighted avg       0.96      0.48      0.63      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.68      0.81       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.68       300\n",
      "   macro avg       0.50      0.84      0.40       300\n",
      "weighted avg       1.00      0.68      0.81       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        86\n",
      "           1       0.98      1.00      0.99      3663\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.49      3749\n",
      "weighted avg       0.95      0.98      0.97      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00     300.0\n",
      "         1.0       0.00      1.00      0.00       0.0\n",
      "\n",
      "    accuracy                           1.00     300.0\n",
      "   macro avg       0.50      0.50      0.00     300.0\n",
      "weighted avg       1.00      0.00      0.00     300.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.33      0.04        86\n",
      "           1       0.98      0.69      0.81      3663\n",
      "\n",
      "    accuracy                           0.68      3749\n",
      "   macro avg       0.50      0.51      0.43      3749\n",
      "weighted avg       0.96      0.68      0.79      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.65      0.79       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.65       300\n",
      "   macro avg       0.50      0.83      0.40       300\n",
      "weighted avg       1.00      0.65      0.79       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for X_train_processed, y_train_processed, method_name in data_list:\n",
    "    svm_model = SVC()\n",
    "    train_feature = train_features[index]\n",
    "    test_feature = test_features[index]\n",
    "    svm_model.fit(train_feature, y_train_processed)\n",
    "    predictions = svm_model.predict(test_feature)\n",
    "    print(classification_report(y_test, predictions))\n",
    "    negative_predictions= svm_model.predict(negative_data_list[index])\n",
    "    print(\n",
    "        classification_report(negative_label_list,\n",
    "                              negative_predictions,\n",
    "                              zero_division=1))\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    negative_accuracy = accuracy_score(negative_label_list, negative_predictions)\n",
    "    performance_data.append({\n",
    "        'Classification Method':\n",
    "        'SVM for VAE data',\n",
    "        'Data Process Method':\n",
    "        method_name,\n",
    "        'Accuracy':\n",
    "        accuracy,\n",
    "        'Precision':\n",
    "        precision,\n",
    "        'Recall':\n",
    "        recall,\n",
    "        'F1 Score':\n",
    "        f1,\n",
    "        'Negative Accuracy':\n",
    "        negative_accuracy,\n",
    "    })\n",
    "    index = index + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost for Desicion Tree for VAE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Original Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        86\n",
      "           1       0.98      1.00      0.99      3663\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.49      3749\n",
      "weighted avg       0.95      0.98      0.97      3749\n",
      "\n",
      "Classification Report for Original Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00     300.0\n",
      "         1.0       0.00      1.00      0.00       0.0\n",
      "\n",
      "    accuracy                           1.00     300.0\n",
      "   macro avg       0.50      0.50      0.00     300.0\n",
      "weighted avg       1.00      0.00      0.00     300.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Over-sampled Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.34      0.04        86\n",
      "           1       0.98      0.67      0.79      3663\n",
      "\n",
      "    accuracy                           0.66      3749\n",
      "   macro avg       0.50      0.50      0.42      3749\n",
      "weighted avg       0.96      0.66      0.78      3749\n",
      "\n",
      "Classification Report for Over-sampled Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.47      0.64       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.47       300\n",
      "   macro avg       0.50      0.73      0.32       300\n",
      "weighted avg       1.00      0.47      0.64       300\n",
      "\n",
      "Classification Report for Under-sampled Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.63      0.06        86\n",
      "           1       0.98      0.52      0.68      3663\n",
      "\n",
      "    accuracy                           0.52      3749\n",
      "   macro avg       0.51      0.57      0.37      3749\n",
      "weighted avg       0.96      0.52      0.66      3749\n",
      "\n",
      "Classification Report for Under-sampled Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.64      0.78       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.64       300\n",
      "   macro avg       0.50      0.82      0.39       300\n",
      "weighted avg       1.00      0.64      0.78       300\n",
      "\n",
      "Classification Report for Tomelinks Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        86\n",
      "           1       0.98      1.00      0.99      3663\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.49      3749\n",
      "weighted avg       0.95      0.98      0.97      3749\n",
      "\n",
      "Classification Report for Tomelinks Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00     300.0\n",
      "         1.0       0.00      1.00      0.00       0.0\n",
      "\n",
      "    accuracy                           1.00     300.0\n",
      "   macro avg       0.50      0.50      0.00     300.0\n",
      "weighted avg       1.00      0.00      0.00     300.0\n",
      "\n",
      "Classification Report for SMOTE Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.40      0.04        86\n",
      "           1       0.98      0.57      0.72      3663\n",
      "\n",
      "    accuracy                           0.57      3749\n",
      "   macro avg       0.50      0.48      0.38      3749\n",
      "weighted avg       0.95      0.57      0.71      3749\n",
      "\n",
      "Classification Report for SMOTE Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.56      0.72       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.56       300\n",
      "   macro avg       0.50      0.78      0.36       300\n",
      "weighted avg       1.00      0.56      0.72       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for X_train_processed, y_train_processed, method_name in data_list:\n",
    "\n",
    "    train_feature = train_features[index]\n",
    "    test_feature = test_features[index]\n",
    "    # 使用决策树桩作为弱分类器，也可以选择其他弱分类器\n",
    "    base_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "    # 使用AdaBoost分类器\n",
    "    adaboost = AdaBoostClassifier(base_classifier,\n",
    "                                  n_estimators=1000,\n",
    "                                  algorithm='SAMME',\n",
    "                                  random_state=42)\n",
    "\n",
    "    # 训练模型\n",
    "    adaboost.fit(train_feature, y_train_processed)\n",
    "\n",
    "    # 在测试集上进行预测和评估\n",
    "    predictions_test = adaboost.predict(test_feature)\n",
    "    print(f\"Classification Report for {method_name} on Test Data:\")\n",
    "    print(classification_report(y_test, predictions_test))\n",
    "\n",
    "    # 在负样本数据上进行预测和评估\n",
    "    predictions_negative = adaboost.predict(negative_data_list[index])\n",
    "    print(f\"Classification Report for {method_name} on Negative Data:\")\n",
    "    print(\n",
    "        classification_report(negative_label_list,\n",
    "                              predictions_negative,\n",
    "                              zero_division=1))\n",
    "    accuracy = accuracy_score(y_test, predictions_test)\n",
    "    precision = precision_score(y_test, predictions_test)\n",
    "    recall = recall_score(y_test, predictions_test)\n",
    "    f1 = f1_score(y_test, predictions_test)\n",
    "    negative_accuracy = accuracy_score(negative_label_list, predictions_negative)\n",
    "    performance_data.append({\n",
    "        'Classification Method': 'AdaBoost for Decision Tree',\n",
    "        'Data Process Method': method_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Negative Accuracy': negative_accuracy,\n",
    "    })\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metrics': 'binary_logloss',\n",
    "    'learning_rate': 0.05,\n",
    "    'reg_lambda': 1.,\n",
    "    'reg_alpha': .1,\n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 100,\n",
    "    'colsample_bytree': .5,\n",
    "    'min_child_samples': 100,\n",
    "    'subsample': .9,\n",
    "    'importance_type': 'gain',\n",
    "    'random_state': 71,\n",
    "    'num_leaves': 32,\n",
    "    'force_col_wise': True,\n",
    "    'scale_pos_weight': 1,\n",
    "    'bagging_freq': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用决策树桩作为弱分类器，也可以选择其他弱分类器\n",
    "base_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# 使用AdaBoost分类器\n",
    "adaboost = AdaBoostClassifier(base_classifier,\n",
    "                              n_estimators=1000,\n",
    "                              algorithm='SAMME',\n",
    "                              random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "adaboost.fit(X_train_under_random, y_train_under_random)\n",
    "\n",
    "# 在测试集上进行预测和评估\n",
    "predictions_ada = adaboost.predict(X_train_under_random)\n",
    "negative_accuracy_1 = adaboost.predict(negative_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用LightGBM分类器\n",
    "lgb_model = lgb.LGBMClassifier(**params, verbose=-1)\n",
    "\n",
    "# 训练模型\n",
    "lgb_model.fit(X_train_under_random, y_train_under_random)\n",
    "\n",
    "# 在测试集上进行预测和评估\n",
    "predictions_lgbm = lgb_model.predict(X_train_under_random)\n",
    "negative_accuracy_2 = lgb_model.predict(negative_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Metrics:\n",
      "Accuracy: 0.8256\n",
      "Precision: 0.7500\n",
      "Recall: 0.8571\n",
      "F1 Score: 0.8000\n",
      "Negative Accuracy: 0.5233\n",
      "Classification Report for Ensemble Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.85        51\n",
      "           1       0.75      0.86      0.80        35\n",
      "\n",
      "    accuracy                           0.83        86\n",
      "   macro avg       0.82      0.83      0.82        86\n",
      "weighted avg       0.83      0.83      0.83        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 创建元模型\n",
    "meta_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 将基模型的预测结果作为特征\n",
    "X_ensemble = np.column_stack((predictions_ada, predictions_lgbm))\n",
    "negative_predictions = np.column_stack((negative_accuracy_1,negative_accuracy_2))\n",
    "\n",
    "# 划分数据集\n",
    "X_train_ensemble, X_test_ensemble, y_train_ensemble, y_test_ensemble = train_test_split(X_ensemble, y_train_under_random, test_size=0.2, random_state=42)\n",
    "\n",
    "# 训练元模型\n",
    "meta_model.fit(X_train_ensemble, y_train_ensemble)\n",
    "\n",
    "# 预测\n",
    "ensemble_predictions = meta_model.predict(X_test_ensemble)\n",
    "negative_predictions = meta_model.predict(negative_predictions)\n",
    "\n",
    "# 计算新的指标\n",
    "accuracy_ensemble = accuracy_score(y_test_ensemble, ensemble_predictions)\n",
    "negative_accuracy_ensemble = accuracy_score(negative_label_list, negative_predictions)\n",
    "precision_ensemble = precision_score(y_test_ensemble, ensemble_predictions)\n",
    "recall_ensemble = recall_score(y_test_ensemble, ensemble_predictions)\n",
    "f1_ensemble = f1_score(y_test_ensemble, ensemble_predictions)\n",
    "\n",
    "# 打印新的指标\n",
    "print(\"Ensemble Model Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_ensemble:.4f}\")\n",
    "print(f\"Precision: {precision_ensemble:.4f}\")\n",
    "print(f\"Recall: {recall_ensemble:.4f}\")\n",
    "print(f\"F1 Score: {f1_ensemble:.4f}\")\n",
    "print(f\"Negative Accuracy: {negative_accuracy_ensemble:.4f}\")\n",
    "\n",
    "# 打印分类报告\n",
    "print(\"Classification Report for Ensemble Model:\")\n",
    "print(classification_report(y_test_ensemble, ensemble_predictions))\n",
    "performance_data.append({\n",
    "    'Classification Method': 'Stacking Ensemble Model for AdaBoost and LightGBM',\n",
    "    'Data Process Method': 'Under-sampled Data',\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1,\n",
    "    'Negative Accuracy': negative_accuracy_ensemble,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Metrics:\n",
      "Accuracy: 0.4425\n",
      "Precision: 0.9828\n",
      "Recall: 0.4371\n",
      "F1 Score: 0.6051\n",
      "Negative Accuracy: 0.6033\n",
      "Classification Report for Ensemble Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.67      0.05        86\n",
      "           1       0.98      0.44      0.61      3663\n",
      "\n",
      "    accuracy                           0.44      3749\n",
      "   macro avg       0.51      0.56      0.33      3749\n",
      "weighted avg       0.96      0.44      0.59      3749\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 创建投票分类器\n",
    "voting_model = VotingClassifier(estimators=[('adaboost', adaboost), ('lgbm', lgb_model)], voting='hard')\n",
    "\n",
    "# 训练投票模型\n",
    "voting_model.fit(X_train_under_random, y_train_under_random)\n",
    "\n",
    "# 预测\n",
    "ensemble_predictions = voting_model.predict(X_test)\n",
    "negative_predictions = voting_model.predict(negative_data)\n",
    "\n",
    "# 计算新的指标\n",
    "accuracy_ensemble = accuracy_score(y_test, ensemble_predictions)\n",
    "negative_accuracy_ensemble = accuracy_score(negative_label_list, negative_predictions)\n",
    "precision_ensemble = precision_score(y_test, ensemble_predictions)\n",
    "recall_ensemble = recall_score(y_test, ensemble_predictions)\n",
    "f1_ensemble = f1_score(y_test, ensemble_predictions)\n",
    "\n",
    "# 打印新的指标\n",
    "print(\"Ensemble Model Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_ensemble:.4f}\")\n",
    "print(f\"Precision: {precision_ensemble:.4f}\")\n",
    "print(f\"Recall: {recall_ensemble:.4f}\")\n",
    "print(f\"F1 Score: {f1_ensemble:.4f}\")\n",
    "print(f\"Negative Accuracy: {negative_accuracy_ensemble:.4f}\")\n",
    "performance_data.append({\n",
    "    'Classification Method': 'Voting Ensemble Model for AdaBoost and LightGBM',\n",
    "    'Data Process Method': 'Under-sampled Data',\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1,\n",
    "    'Negative Accuracy': negative_accuracy_ensemble,\n",
    "})\n",
    "\n",
    "# 打印分类报告\n",
    "print(\"Classification Report for Ensemble Model:\")\n",
    "print(classification_report(y_test, ensemble_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for the method: Original Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 249\n",
      "Training for the method: Over-sampled Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 249\n",
      "Training for the method: Under-sampled Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 249\n",
      "Training for the method: Tomelinks Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 249\n",
      "Training for the method: SMOTE Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "Anomal_model_list = []\n",
    "\n",
    "for X_train_processed, _, method_name in data_list:\n",
    "   print(\"Training for the method: \" + method_name)\n",
    "   model = train_vae_anomaly_detection(X_train=X_train_processed,X_test=X_test, progress=True,num_epoch=250).eval()\n",
    "   Anomal_model_list.append(model)\n",
    "\n",
    "Anomal_list = [ t+ (data,)  for t, data in zip(data_list, Anomal_model_list)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        86\n",
      "           1       0.98      1.00      0.99      3663\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.49      3749\n",
      "weighted avg       0.95      0.98      0.97      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00     300.0\n",
      "         1.0       0.00      1.00      0.00       0.0\n",
      "\n",
      "    accuracy                           1.00     300.0\n",
      "   macro avg       0.50      0.50      0.00     300.0\n",
      "weighted avg       1.00      0.00      0.00     300.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        86\n",
      "           1       0.98      1.00      0.99      3663\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.49      3749\n",
      "weighted avg       0.95      0.98      0.97      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00     300.0\n",
      "         1.0       0.00      1.00      0.00       0.0\n",
      "\n",
      "    accuracy                           1.00     300.0\n",
      "   macro avg       0.50      0.50      0.00     300.0\n",
      "weighted avg       1.00      0.00      0.00     300.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        86\n",
      "           1       0.98      1.00      0.99      3663\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.49      3749\n",
      "weighted avg       0.95      0.98      0.97      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00     300.0\n",
      "         1.0       0.00      1.00      0.00       0.0\n",
      "\n",
      "    accuracy                           1.00     300.0\n",
      "   macro avg       0.50      0.50      0.00     300.0\n",
      "weighted avg       1.00      0.00      0.00     300.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        86\n",
      "           1       0.98      1.00      0.99      3663\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.49      3749\n",
      "weighted avg       0.95      0.98      0.97      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00     300.0\n",
      "         1.0       0.00      1.00      0.00       0.0\n",
      "\n",
      "    accuracy                           1.00     300.0\n",
      "   macro avg       0.50      0.50      0.00     300.0\n",
      "weighted avg       1.00      0.00      0.00     300.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        86\n",
      "           1       0.98      1.00      0.99      3663\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.49      3749\n",
      "weighted avg       0.95      0.98      0.97      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00     300.0\n",
      "         1.0       0.00      1.00      0.00       0.0\n",
      "\n",
      "    accuracy                           1.00     300.0\n",
      "   macro avg       0.50      0.50      0.00     300.0\n",
      "weighted avg       1.00      0.00      0.00     300.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print(len(Anomal_list))\n",
    "for X_train_processed, _, method_name, model in Anomal_list:\n",
    "    predictions = model.predict_anomaly(\n",
    "        torch.Tensor(X_test).to(device),\n",
    "        threshold=0.05).detach().cpu().numpy()\n",
    "    negative_data_pred = model.predict_anomaly(\n",
    "        torch.Tensor(negative_data).to(device),\n",
    "        threshold=0.05).detach().cpu().numpy()\n",
    "\n",
    "    # 计算评估指标\n",
    "    report_test = classification_report(y_test, predictions, output_dict=True)\n",
    "    report_negative = classification_report(negative_label_list, negative_data_pred, output_dict=True, zero_division=1)\n",
    "\n",
    "    # 提取指标\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = report_test['1']['precision']\n",
    "    recall = report_test['1']['recall']\n",
    "    f1 = report_test['1']['f1-score']\n",
    "    negative_accuracy = accuracy_score(negative_label_list, negative_data_pred)\n",
    "\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(\n",
    "        classification_report(negative_label_list,\n",
    "                              negative_data_pred,\n",
    "                              zero_division=1))\n",
    "    # 添加到 performance_data 列表中\n",
    "    performance_data.append({\n",
    "        'Classification Method': 'Anomaly Detection with VAE',\n",
    "        'Data Process Method': method_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Negative Accuracy': negative_accuracy,\n",
    "    })\n",
    "\n",
    "    index += 1\n",
    "\n",
    "# 将列表转换为 DataFrame\n",
    "df_performance = pd.DataFrame(performance_data)\n",
    "df_performance.to_csv('performance_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Classification Method': 'LightGBM for VAE data', 'Data Process Method': 'Original Data', 'Accuracy': 0.9770605494798613, 'Precision': 0.9770605494798613, 'Recall': 1.0, 'F1 Score': 0.9883971937398812, 'Negative Accuracy': 0.0}, {'Classification Method': 'LightGBM for VAE data', 'Data Process Method': 'Over-sampled Data', 'Accuracy': 0.7951453720992264, 'Precision': 0.9788289778365862, 'Recall': 0.8078078078078078, 'F1 Score': 0.8851331139694885, 'Negative Accuracy': 0.33666666666666667}, {'Classification Method': 'LightGBM for VAE data', 'Data Process Method': 'Under-sampled Data', 'Accuracy': 0.48306214990664176, 'Precision': 0.9826524902070509, 'Recall': 0.4793884793884794, 'F1 Score': 0.6444036697247707, 'Negative Accuracy': 0.5666666666666667}, {'Classification Method': 'LightGBM for VAE data', 'Data Process Method': 'Tomelinks Data', 'Accuracy': 0.9770605494798613, 'Precision': 0.9770605494798613, 'Recall': 1.0, 'F1 Score': 0.9883971937398812, 'Negative Accuracy': 0.0}, {'Classification Method': 'LightGBM for VAE data', 'Data Process Method': 'SMOTE Data', 'Accuracy': 0.6351026940517471, 'Precision': 0.9779258642232403, 'Recall': 0.641004641004641, 'F1 Score': 0.7744063324538258, 'Negative Accuracy': 0.6166666666666667}, {'Classification Method': 'SVM for VAE data', 'Data Process Method': 'Original Data', 'Accuracy': 0.9770605494798613, 'Precision': 0.9770605494798613, 'Recall': 1.0, 'F1 Score': 0.9883971937398812, 'Negative Accuracy': 0.0}, {'Classification Method': 'SVM for VAE data', 'Data Process Method': 'Over-sampled Data', 'Accuracy': 0.7682048546279008, 'Precision': 0.9810606060606061, 'Recall': 0.7777777777777778, 'F1 Score': 0.8676716917922949, 'Negative Accuracy': 0.5466666666666666}, {'Classification Method': 'SVM for VAE data', 'Data Process Method': 'Under-sampled Data', 'Accuracy': 0.48492931448386234, 'Precision': 0.9795127353266888, 'Recall': 0.48293748293748295, 'F1 Score': 0.6469189979886634, 'Negative Accuracy': 0.68}, {'Classification Method': 'SVM for VAE data', 'Data Process Method': 'Tomelinks Data', 'Accuracy': 0.9770605494798613, 'Precision': 0.9770605494798613, 'Recall': 1.0, 'F1 Score': 0.9883971937398812, 'Negative Accuracy': 0.0}, {'Classification Method': 'SVM for VAE data', 'Data Process Method': 'SMOTE Data', 'Accuracy': 0.6809815950920245, 'Precision': 0.9775454897406117, 'Recall': 0.6893256893256893, 'F1 Score': 0.8085174511687481, 'Negative Accuracy': 0.6533333333333333}, {'Classification Method': 'AdaBoost for Decision Tree', 'Data Process Method': 'Original Data', 'Accuracy': 0.9770605494798613, 'Precision': 0.9770605494798613, 'Recall': 1.0, 'F1 Score': 0.9883971937398812, 'Negative Accuracy': 0.0}, {'Classification Method': 'AdaBoost for Decision Tree', 'Data Process Method': 'Over-sampled Data', 'Accuracy': 0.660442784742598, 'Precision': 0.9772364217252396, 'Recall': 0.668031668031668, 'F1 Score': 0.7935787254742988, 'Negative Accuracy': 0.4666666666666667}, {'Classification Method': 'AdaBoost for Decision Tree', 'Data Process Method': 'Under-sampled Data', 'Accuracy': 0.519871965857562, 'Precision': 0.9833938764919564, 'Recall': 0.5173355173355173, 'F1 Score': 0.6779964221824687, 'Negative Accuracy': 0.6433333333333333}, {'Classification Method': 'AdaBoost for Decision Tree', 'Data Process Method': 'Tomelinks Data', 'Accuracy': 0.9765270738863697, 'Precision': 0.9770483053109154, 'Recall': 0.9994539994539995, 'F1 Score': 0.9881241565452091, 'Negative Accuracy': 0.0}, {'Classification Method': 'AdaBoost for Decision Tree', 'Data Process Method': 'SMOTE Data', 'Accuracy': 0.570285409442518, 'Precision': 0.9758812615955473, 'Recall': 0.5743925743925744, 'F1 Score': 0.7231483072692902, 'Negative Accuracy': 0.56}, {'Classification Method': 'Stacking Ensemble Model for AdaBoost and LightGBM', 'Data Process Method': 'Under-sampled Data', 'Accuracy': 0.570285409442518, 'Precision': 0.9758812615955473, 'Recall': 0.5743925743925744, 'F1 Score': 0.7231483072692902, 'Negative Accuracy': 0.5233333333333333}, {'Classification Method': 'Voting Ensemble Model for AdaBoost and LightGBM', 'Data Process Method': 'Under-sampled Data', 'Accuracy': 0.570285409442518, 'Precision': 0.9758812615955473, 'Recall': 0.5743925743925744, 'F1 Score': 0.7231483072692902, 'Negative Accuracy': 0.6033333333333334}, {'Classification Method': 'Anomaly Detection with VAE', 'Data Process Method': 'Original Data', 'Accuracy': 0.9770605494798613, 'Precision': 0.9770605494798613, 'Recall': 1.0, 'F1 Score': 0.9883971937398812, 'Negative Accuracy': 0.0}, {'Classification Method': 'Anomaly Detection with VAE', 'Data Process Method': 'Over-sampled Data', 'Accuracy': 0.9770605494798613, 'Precision': 0.9770605494798613, 'Recall': 1.0, 'F1 Score': 0.9883971937398812, 'Negative Accuracy': 0.0}, {'Classification Method': 'Anomaly Detection with VAE', 'Data Process Method': 'Under-sampled Data', 'Accuracy': 0.9770605494798613, 'Precision': 0.9770605494798613, 'Recall': 1.0, 'F1 Score': 0.9883971937398812, 'Negative Accuracy': 0.0}, {'Classification Method': 'Anomaly Detection with VAE', 'Data Process Method': 'Tomelinks Data', 'Accuracy': 0.9770605494798613, 'Precision': 0.9770605494798613, 'Recall': 1.0, 'F1 Score': 0.9883971937398812, 'Negative Accuracy': 0.0}, {'Classification Method': 'Anomaly Detection with VAE', 'Data Process Method': 'SMOTE Data', 'Accuracy': 0.9770605494798613, 'Precision': 0.9770605494798613, 'Recall': 1.0, 'F1 Score': 0.9883971937398812, 'Negative Accuracy': 0.0}]\n",
      "best Accuracy Classification Method: LightGBM for VAE data\n",
      "Best Accuracy Data Process Method: Original Data\n",
      "Best Accuracy Value: 0.977\n",
      "best Accuracy Classification Method: LightGBM for VAE data\n",
      "Best Precision Data Process Method: Under-sampled Data\n",
      "Best Precision Value: 0.983\n",
      "best Accuracy Classification Method: LightGBM for VAE data\n",
      "Best Recall Data Process Method: Original Data\n",
      "Best Recall Value: 1.0\n",
      "best Accuracy Classification Method: LightGBM for VAE data\n",
      "Best F1 Score Data Process Method: Original Data\n",
      "Best F1 Score Value: 0.988\n",
      "best Accuracy Classification Method: SVM for VAE data\n",
      "Best Negative Accuracy Data Process Method: Under-sampled Data\n",
      "Best Negative Accuracy Value: 0.68\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.DataFrame(performance_data)\n",
    "data_df = data_df.round({'Accuracy': 3, 'Precision': 3, 'Recall': 3, 'F1 Score': 3, 'Negative Accuracy': 3})\n",
    "\n",
    "# 找到最佳性能数据的行\n",
    "best_accuracy_row = data_df[data_df['Accuracy'] == data_df['Accuracy'].max()]\n",
    "best_precision_row = data_df[data_df['Precision'] == data_df['Precision'].max()]\n",
    "best_recall_row = data_df[data_df['Recall'] == data_df['Recall'].max()]\n",
    "best_f1_score_row = data_df[data_df['F1 Score'] == data_df['F1 Score'].max()]\n",
    "best_negative_accuracy_row = data_df[data_df['Negative Accuracy'] == data_df['Negative Accuracy'].max()]\n",
    "\n",
    "# 输出最佳性能数据\n",
    "print(\"best Accuracy Classification Method:\", best_accuracy_row['Classification Method'].values[0])\n",
    "print(\"Best Accuracy Data Process Method:\", best_accuracy_row['Data Process Method'].values[0])\n",
    "print(\"Best Accuracy Value:\", best_accuracy_row['Accuracy'].values[0])\n",
    "\n",
    "print(\"best Accuracy Classification Method:\", best_precision_row['Classification Method'].values[0])\n",
    "print(\"Best Precision Data Process Method:\", best_precision_row['Data Process Method'].values[0])\n",
    "print(\"Best Precision Value:\", best_precision_row['Precision'].values[0])\n",
    "\n",
    "print(\"best Accuracy Classification Method:\", best_recall_row['Classification Method'].values[0])\n",
    "print(\"Best Recall Data Process Method:\", best_recall_row['Data Process Method'].values[0])\n",
    "print(\"Best Recall Value:\", best_recall_row['Recall'].values[0])\n",
    "\n",
    "print(\"best Accuracy Classification Method:\", best_f1_score_row['Classification Method'].values[0])\n",
    "print(\"Best F1 Score Data Process Method:\", best_f1_score_row['Data Process Method'].values[0])\n",
    "print(\"Best F1 Score Value:\", best_f1_score_row['F1 Score'].values[0])\n",
    "\n",
    "\n",
    "print(\"best Accuracy Classification Method:\", best_negative_accuracy_row['Classification Method'].values[0])\n",
    "print(\"Best Negative Accuracy Data Process Method:\", best_negative_accuracy_row['Data Process Method'].values[0])\n",
    "print(\"Best Negative Accuracy Value:\", best_negative_accuracy_row['Negative Accuracy'].values[0])\n",
    "data_df.to_csv('output/performance_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
