{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引入必要库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed libraries、\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "from VAE_pipeline import train_vae\n",
    "\n",
    "# 选择设备\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 438557 entries, 0 to 438556\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   ID                   438557 non-null  int64  \n",
      " 1   CODE_GENDER          438557 non-null  object \n",
      " 2   FLAG_OWN_CAR         438557 non-null  object \n",
      " 3   FLAG_OWN_REALTY      438557 non-null  object \n",
      " 4   CNT_CHILDREN         438557 non-null  int64  \n",
      " 5   AMT_INCOME_TOTAL     438557 non-null  float64\n",
      " 6   NAME_INCOME_TYPE     438557 non-null  object \n",
      " 7   NAME_EDUCATION_TYPE  438557 non-null  object \n",
      " 8   NAME_FAMILY_STATUS   438557 non-null  object \n",
      " 9   NAME_HOUSING_TYPE    438557 non-null  object \n",
      " 10  DAYS_BIRTH           438557 non-null  int64  \n",
      " 11  DAYS_EMPLOYED        438557 non-null  int64  \n",
      " 12  FLAG_MOBIL           438557 non-null  int64  \n",
      " 13  FLAG_WORK_PHONE      438557 non-null  int64  \n",
      " 14  FLAG_PHONE           438557 non-null  int64  \n",
      " 15  FLAG_EMAIL           438557 non-null  int64  \n",
      " 16  OCCUPATION_TYPE      304354 non-null  object \n",
      " 17  CNT_FAM_MEMBERS      438557 non-null  float64\n",
      "dtypes: float64(2), int64(8), object(8)\n",
      "memory usage: 60.2+ MB\n",
      "None\n",
      "ID                     438510\n",
      "CODE_GENDER                 2\n",
      "FLAG_OWN_CAR                2\n",
      "FLAG_OWN_REALTY             2\n",
      "CNT_CHILDREN               12\n",
      "AMT_INCOME_TOTAL          866\n",
      "NAME_INCOME_TYPE            5\n",
      "NAME_EDUCATION_TYPE         5\n",
      "NAME_FAMILY_STATUS          5\n",
      "NAME_HOUSING_TYPE           6\n",
      "DAYS_BIRTH              16379\n",
      "DAYS_EMPLOYED            9406\n",
      "FLAG_MOBIL                  1\n",
      "FLAG_WORK_PHONE             2\n",
      "FLAG_PHONE                  2\n",
      "FLAG_EMAIL                  2\n",
      "OCCUPATION_TYPE            18\n",
      "CNT_FAM_MEMBERS            13\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_application_record = pd.read_csv(\"application_record.csv\")\n",
    "df_credit_record = pd.read_csv(\"credit_record.csv\")\n",
    "\n",
    "print(df_application_record.info())\n",
    "print(df_application_record.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 438463 entries, 0 to 438556\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   ID                   438463 non-null  int64  \n",
      " 1   CODE_GENDER          438463 non-null  object \n",
      " 2   FLAG_OWN_CAR         438463 non-null  object \n",
      " 3   FLAG_OWN_REALTY      438463 non-null  object \n",
      " 4   CNT_CHILDREN         438463 non-null  int64  \n",
      " 5   AMT_INCOME_TOTAL     438463 non-null  float64\n",
      " 6   NAME_INCOME_TYPE     438463 non-null  object \n",
      " 7   NAME_EDUCATION_TYPE  438463 non-null  object \n",
      " 8   NAME_FAMILY_STATUS   438463 non-null  object \n",
      " 9   NAME_HOUSING_TYPE    438463 non-null  object \n",
      " 10  DAYS_BIRTH           438463 non-null  int64  \n",
      " 11  DAYS_EMPLOYED        438463 non-null  int64  \n",
      " 12  FLAG_MOBIL           438463 non-null  int64  \n",
      " 13  FLAG_WORK_PHONE      438463 non-null  int64  \n",
      " 14  FLAG_PHONE           438463 non-null  int64  \n",
      " 15  FLAG_EMAIL           438463 non-null  int64  \n",
      " 16  OCCUPATION_TYPE      304286 non-null  object \n",
      " 17  CNT_FAM_MEMBERS      438463 non-null  float64\n",
      "dtypes: float64(2), int64(8), object(8)\n",
      "memory usage: 63.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#For each set of duplicate ID's drop both of them\n",
    "df_application_record = df_application_record.drop_duplicates(subset = 'ID', keep = False)\n",
    "print(df_application_record.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count    Dtype \n",
      "---  ------          --------------    ----- \n",
      " 0   ID              1048575 non-null  int64 \n",
      " 1   MONTHS_BALANCE  1048575 non-null  int64 \n",
      " 2   STATUS          1048575 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 24.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_credit_record.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique IDs that are consistent between both datasets 36457\n",
      "New # of IDs in application_record 36457\n",
      "New # of IDs in credit_record 36457\n"
     ]
    }
   ],
   "source": [
    "#show how many unique IDs we will be able to work with in the dataframes\n",
    "print(\"# of unique IDs that are consistent between both datasets\", df_application_record[df_application_record['ID'].isin(df_credit_record['ID'])]['ID'].nunique())\n",
    "\n",
    "#adjust the dataframes so that we only work with the consistent IDs\n",
    "df_application_record = df_application_record[df_application_record['ID'].isin(df_credit_record['ID'])]\n",
    "df_credit_record = df_credit_record[df_credit_record['ID'].isin(df_application_record['ID'])]\n",
    "print(\"New # of IDs in application_record\", df_application_record['ID'].nunique())\n",
    "print(\"New # of IDs in credit_record\", df_credit_record['ID'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATUS\n",
      "C    329536\n",
      "0    290654\n",
      "1      8747\n",
      "5      1527\n",
      "2       801\n",
      "3       286\n",
      "4       214\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_credit_record['APPROVED'] = df_credit_record['STATUS'].map({'1':0,'2':0,'3':0,'4':0,'5':0,'X':-1,'C':1,'0':1})\n",
    "df_credit_record = df_credit_record[df_credit_record['APPROVED']!=-1]\n",
    "print(df_credit_record['STATUS'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
      "0  5008804           M            Y               Y             0   \n",
      "1  5008804           M            Y               Y             0   \n",
      "2  5008804           M            Y               Y             0   \n",
      "3  5008804           M            Y               Y             0   \n",
      "4  5008804           M            Y               Y             0   \n",
      "\n",
      "   AMT_INCOME_TOTAL NAME_INCOME_TYPE NAME_EDUCATION_TYPE NAME_FAMILY_STATUS  \\\n",
      "0          427500.0          Working    Higher education     Civil marriage   \n",
      "1          427500.0          Working    Higher education     Civil marriage   \n",
      "2          427500.0          Working    Higher education     Civil marriage   \n",
      "3          427500.0          Working    Higher education     Civil marriage   \n",
      "4          427500.0          Working    Higher education     Civil marriage   \n",
      "\n",
      "  NAME_HOUSING_TYPE  ...  DAYS_EMPLOYED  FLAG_MOBIL  FLAG_WORK_PHONE  \\\n",
      "0  Rented apartment  ...          -4542           1                1   \n",
      "1  Rented apartment  ...          -4542           1                1   \n",
      "2  Rented apartment  ...          -4542           1                1   \n",
      "3  Rented apartment  ...          -4542           1                1   \n",
      "4  Rented apartment  ...          -4542           1                1   \n",
      "\n",
      "   FLAG_PHONE  FLAG_EMAIL  OCCUPATION_TYPE CNT_FAM_MEMBERS  MONTHS_BALANCE  \\\n",
      "0           0           0              NaN             2.0               0   \n",
      "1           0           0              NaN             2.0              -1   \n",
      "2           0           0              NaN             2.0              -2   \n",
      "3           0           0              NaN             2.0              -3   \n",
      "4           0           0              NaN             2.0              -4   \n",
      "\n",
      "   STATUS APPROVED  \n",
      "0       C        1  \n",
      "1       C        1  \n",
      "2       C        1  \n",
      "3       C        1  \n",
      "4       C        1  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "df_application_record = df_application_record.merge(df_credit_record, on='ID')\n",
    "print(df_application_record.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                     0\n",
      "CODE_GENDER            0\n",
      "FLAG_OWN_CAR           0\n",
      "FLAG_OWN_REALTY        0\n",
      "CNT_CHILDREN           0\n",
      "AMT_INCOME_TOTAL       0\n",
      "NAME_INCOME_TYPE       0\n",
      "NAME_EDUCATION_TYPE    0\n",
      "NAME_FAMILY_STATUS     0\n",
      "NAME_HOUSING_TYPE      0\n",
      "DAYS_BIRTH             0\n",
      "DAYS_EMPLOYED          0\n",
      "FLAG_MOBIL             0\n",
      "FLAG_WORK_PHONE        0\n",
      "FLAG_PHONE             0\n",
      "FLAG_EMAIL             0\n",
      "OCCUPATION_TYPE        0\n",
      "CNT_FAM_MEMBERS        0\n",
      "MONTHS_BALANCE         0\n",
      "STATUS                 0\n",
      "APPROVED               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_application_record = df_application_record[df_application_record['MONTHS_BALANCE']==-4]\n",
    "df_application_record.loc[df_application_record[\"NAME_INCOME_TYPE\"]==\"Pensioner\",\"OCCUPATION_TYPE\"] = \"Pension\"\n",
    "df_application_record.loc[df_application_record[\"NAME_INCOME_TYPE\"]==\"Commercial associate\",\"OCCUPATION_TYPE\"] = \"Commercial associate\"\n",
    "df_application_record.loc[df_application_record[\"NAME_INCOME_TYPE\"]==\"State servant\",\"OCCUPATION_TYPE\"] = \"State servant\"\n",
    "df_application_record.loc[df_application_record[\"NAME_INCOME_TYPE\"]==\"Student\",\"OCCUPATION_TYPE\"] = \"Student\"\n",
    "df_application_record = df_application_record.dropna()\n",
    "print(df_application_record.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
      "33   5008806           M            Y               Y             0   \n",
      "49   5008810           F            N               Y             0   \n",
      "70   5008811           F            N               Y             0   \n",
      "145  5008815           M            Y               Y             0   \n",
      "148  5112956           M            Y               Y             0   \n",
      "\n",
      "     AMT_INCOME_TOTAL      NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
      "33           112500.0               Working  Secondary / secondary special   \n",
      "49           270000.0  Commercial associate  Secondary / secondary special   \n",
      "70           270000.0  Commercial associate  Secondary / secondary special   \n",
      "145          270000.0               Working               Higher education   \n",
      "148          270000.0               Working               Higher education   \n",
      "\n",
      "       NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_BIRTH  FLAG_MOBIL  \\\n",
      "33                Married  House / apartment      -21474           1   \n",
      "49   Single / not married  House / apartment      -19110           1   \n",
      "70   Single / not married  House / apartment      -19110           1   \n",
      "145               Married  House / apartment      -16872           1   \n",
      "148               Married  House / apartment      -16872           1   \n",
      "\n",
      "     FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL       OCCUPATION_TYPE  \\\n",
      "33                 0           0           0        Security staff   \n",
      "49                 0           1           1  Commercial associate   \n",
      "70                 0           1           1  Commercial associate   \n",
      "145                1           1           1           Accountants   \n",
      "148                1           1           1           Accountants   \n",
      "\n",
      "     CNT_FAM_MEMBERS  MONTHS_BALANCE  APPROVED  Work_Time  \n",
      "33               2.0              -4         1          3  \n",
      "49               1.0              -4         1          8  \n",
      "70               1.0              -4         1          8  \n",
      "145              2.0              -4         1          2  \n",
      "148              2.0              -4         1          2  \n"
     ]
    }
   ],
   "source": [
    "df_application_record['Work_Time'] = -(df_application_record['DAYS_EMPLOYED'])//365\n",
    "\n",
    "df_application_record = df_application_record.drop(df_application_record[df_application_record['Work_Time']>50].index)\n",
    "df_application_record = df_application_record.drop(df_application_record[df_application_record['Work_Time']<0].index)\n",
    "# df_application_record['Work_Time'].plot(kind='hist',bins=20,density=True)\n",
    "df_application_record = df_application_record.drop(columns=['STATUS'])\n",
    "df_application_record.drop(['DAYS_EMPLOYED'],axis=1,inplace=True)\n",
    "print(df_application_record.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                     0\n",
      "CODE_GENDER            0\n",
      "FLAG_OWN_CAR           0\n",
      "FLAG_OWN_REALTY        0\n",
      "CNT_CHILDREN           0\n",
      "AMT_INCOME_TOTAL       0\n",
      "NAME_INCOME_TYPE       0\n",
      "NAME_EDUCATION_TYPE    0\n",
      "NAME_FAMILY_STATUS     0\n",
      "NAME_HOUSING_TYPE      0\n",
      "FLAG_MOBIL             0\n",
      "FLAG_WORK_PHONE        0\n",
      "FLAG_PHONE             0\n",
      "FLAG_EMAIL             0\n",
      "OCCUPATION_TYPE        0\n",
      "CNT_FAM_MEMBERS        0\n",
      "MONTHS_BALANCE         0\n",
      "APPROVED               0\n",
      "Work_Time              0\n",
      "AGE                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "baseline_date = pd.to_datetime('2023-01-01')\n",
    "df_application_record['BIRTH_DATE'] = baseline_date + pd.to_timedelta(df_application_record['DAYS_BIRTH'], unit='D')\n",
    "df_application_record['AGE'] = (baseline_date - df_application_record['BIRTH_DATE']).dt.days // 365\n",
    "df_application_record = df_application_record.drop(columns=['DAYS_BIRTH','BIRTH_DATE'])\n",
    "print(df_application_record.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPROVED\n",
      "1    14693\n",
      "0      300\n",
      "Name: count, dtype: int64\n",
      "Index(['ID', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN',\n",
      "       'AMT_INCOME_TOTAL', 'NAME_FAMILY_STATUS', 'FLAG_MOBIL',\n",
      "       'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL', 'CNT_FAM_MEMBERS',\n",
      "       'MONTHS_BALANCE', 'APPROVED', 'Work_Time', 'AGE',\n",
      "       'NAME_INCOME_TYPE_Commercial associate', 'NAME_INCOME_TYPE_Pensioner',\n",
      "       'NAME_INCOME_TYPE_State servant', 'NAME_INCOME_TYPE_Student',\n",
      "       'NAME_INCOME_TYPE_Working', 'NAME_EDUCATION_TYPE_Academic degree',\n",
      "       'NAME_EDUCATION_TYPE_Higher education',\n",
      "       'NAME_EDUCATION_TYPE_Incomplete higher',\n",
      "       'NAME_EDUCATION_TYPE_Lower secondary',\n",
      "       'NAME_EDUCATION_TYPE_Secondary / secondary special',\n",
      "       'NAME_HOUSING_TYPE_Co-op apartment',\n",
      "       'NAME_HOUSING_TYPE_House / apartment',\n",
      "       'NAME_HOUSING_TYPE_Municipal apartment',\n",
      "       'NAME_HOUSING_TYPE_Office apartment',\n",
      "       'NAME_HOUSING_TYPE_Rented apartment', 'NAME_HOUSING_TYPE_With parents',\n",
      "       'OCCUPATION_TYPE_Accountants', 'OCCUPATION_TYPE_Cleaning staff',\n",
      "       'OCCUPATION_TYPE_Commercial associate', 'OCCUPATION_TYPE_Cooking staff',\n",
      "       'OCCUPATION_TYPE_Core staff', 'OCCUPATION_TYPE_Drivers',\n",
      "       'OCCUPATION_TYPE_HR staff', 'OCCUPATION_TYPE_High skill tech staff',\n",
      "       'OCCUPATION_TYPE_IT staff', 'OCCUPATION_TYPE_Laborers',\n",
      "       'OCCUPATION_TYPE_Low-skill Laborers', 'OCCUPATION_TYPE_Managers',\n",
      "       'OCCUPATION_TYPE_Medicine staff', 'OCCUPATION_TYPE_Pension',\n",
      "       'OCCUPATION_TYPE_Private service staff',\n",
      "       'OCCUPATION_TYPE_Realty agents', 'OCCUPATION_TYPE_Sales staff',\n",
      "       'OCCUPATION_TYPE_Secretaries', 'OCCUPATION_TYPE_Security staff',\n",
      "       'OCCUPATION_TYPE_State servant', 'OCCUPATION_TYPE_Student',\n",
      "       'OCCUPATION_TYPE_Waiters/barmen staff'],\n",
      "      dtype='object')\n",
      "          ID  CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
      "33   5008806            0             0                0             0   \n",
      "49   5008810            1             1                0             0   \n",
      "70   5008811            1             1                0             0   \n",
      "145  5008815            0             0                0             0   \n",
      "148  5112956            0             0                0             0   \n",
      "\n",
      "     AMT_INCOME_TOTAL  NAME_FAMILY_STATUS  FLAG_MOBIL  FLAG_WORK_PHONE  \\\n",
      "33           112500.0                   0           1                0   \n",
      "49           270000.0                   1           1                0   \n",
      "70           270000.0                   1           1                0   \n",
      "145          270000.0                   0           1                1   \n",
      "148          270000.0                   0           1                1   \n",
      "\n",
      "     FLAG_PHONE  ...  OCCUPATION_TYPE_Medicine staff  OCCUPATION_TYPE_Pension  \\\n",
      "33            0  ...                           False                    False   \n",
      "49            1  ...                           False                    False   \n",
      "70            1  ...                           False                    False   \n",
      "145           1  ...                           False                    False   \n",
      "148           1  ...                           False                    False   \n",
      "\n",
      "     OCCUPATION_TYPE_Private service staff  OCCUPATION_TYPE_Realty agents  \\\n",
      "33                                   False                          False   \n",
      "49                                   False                          False   \n",
      "70                                   False                          False   \n",
      "145                                  False                          False   \n",
      "148                                  False                          False   \n",
      "\n",
      "     OCCUPATION_TYPE_Sales staff  OCCUPATION_TYPE_Secretaries  \\\n",
      "33                         False                        False   \n",
      "49                         False                        False   \n",
      "70                         False                        False   \n",
      "145                        False                        False   \n",
      "148                        False                        False   \n",
      "\n",
      "     OCCUPATION_TYPE_Security staff  OCCUPATION_TYPE_State servant  \\\n",
      "33                             True                          False   \n",
      "49                            False                          False   \n",
      "70                            False                          False   \n",
      "145                           False                          False   \n",
      "148                           False                          False   \n",
      "\n",
      "     OCCUPATION_TYPE_Student  OCCUPATION_TYPE_Waiters/barmen staff  \n",
      "33                     False                                 False  \n",
      "49                     False                                 False  \n",
      "70                     False                                 False  \n",
      "145                    False                                 False  \n",
      "148                    False                                 False  \n",
      "\n",
      "[5 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['CODE_GENDER', 'NAME_FAMILY_STATUS', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']\n",
    "dummy_columns = ['NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE']\n",
    "categorical_df = df_application_record[categorical_columns]\n",
    "categorical_df = categorical_df.apply(lambda x: pd.factorize(x)[0])\n",
    "categorical_df = pd.DataFrame(categorical_df)\n",
    "df_application_record[categorical_columns] = categorical_df\n",
    "df_application_record = pd.get_dummies(df_application_record, columns=dummy_columns)\n",
    "print(df_application_record['APPROVED'].value_counts())\n",
    "df_application_record.to_csv('dataset.csv', index=False)\n",
    "print(df_application_record.columns)\n",
    "print(df_application_record.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# df_application_record['AMT_INCOME_TOTAL']=scaler.fit_transform(df_application_record['AMT_INCOME_TOTAL'].values.reshape(-1, 1))\n",
    "# df_application_record['DAYS_EMPLOYED']=scaler.fit_transform(df_application_record['DAYS_EMPLOYED'].values.reshape(-1, 1))\n",
    "# df_application_record['MONTHS_BALANCE']=scaler.fit_transform(df_application_record['MONTHS_BALANCE'].values.reshape(-1, 1))\n",
    "# scaler = StandardScaler()\n",
    "# df_application_record['CNT_FAM_MEMBERS']=scaler.fit_transform(df_application_record['CNT_FAM_MEMBERS'].values.reshape(-1, 1))\n",
    "# df_application_record['AGE']=scaler.fit_transform(df_application_record['AGE'].values.reshape(-1, 1))\n",
    "\n",
    "negative_data_orgin = df_application_record[df_application_record['APPROVED']==0]\n",
    "negative_data = negative_data_orgin.drop(['APPROVED', 'ID','CODE_GENDER'], axis = 1)\n",
    "\n",
    "X = df_application_record.drop(['APPROVED', 'ID','CODE_GENDER'], axis = 1)\n",
    "y = df_application_record['APPROVED']\n",
    "X = np.array(X,dtype=float)\n",
    "y = np.array(y, dtype=int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "scalar = StandardScaler()\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_test = scalar.fit_transform(X_test)\n",
    "\n",
    "negative_data = scalar.fit_transform(np.array(negative_data,dtype=float))\n",
    "negative_label_list = np.zeros(len(negative_data))\n",
    "\n",
    "\n",
    "# 创建 RandomUnderSampler 对象\n",
    "undersampler = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "# 使用 RandomUnderSampler 来生成平衡的训练集\n",
    "X_train_under_random, y_train_under_random = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# 创建RandomOverSampler对象\n",
    "oversampler = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "# 使用RandomOverSampler来生成平衡的训练集\n",
    "X_train_over_random, y_train_over_random = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# 创建TomekLinks对象\n",
    "undersampler = TomekLinks()\n",
    "\n",
    "# 使用TomekLinks来生成平衡的训练集\n",
    "X_train_under_tomelinks, y_train_under_tomelinks = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# 创建SMOTE对象\n",
    "smote = SMOTE(sampling_strategy='minority',random_state=42)\n",
    "\n",
    "# 使用SMOTE来生成平衡的训练集\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [\n",
    "             (X_train, y_train, \"Original Data\"),\n",
    "            #  (X_train_over_random,y_train_over_random, \"Over-sampled Data\"),\n",
    "             (X_train_under_random,y_train_under_random, \"Under-sampled Data\"),\n",
    "            #  (X_train_under_tomelinks,y_train_under_tomelinks, \"Tomelinks Data\"),\n",
    "             (X_train_smote,y_train_smote, \"SMOTE Data\")\n",
    "            ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_data= []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metrics': 'binary_logloss',\n",
    "    'learning_rate': 0.05,\n",
    "    'reg_lambda': 1.,\n",
    "    'reg_alpha': .1,\n",
    "    'max_depth': 5,\n",
    "    'n_estimators': 100,\n",
    "    'colsample_bytree': .5,\n",
    "    'min_child_samples': 100,\n",
    "    'subsample': .9,\n",
    "    'importance_type': 'gain',\n",
    "    'random_state': 71,\n",
    "    'num_leaves': 32,\n",
    "    'force_col_wise': True,\n",
    "    'scale_pos_weight': 1,\n",
    "    'bagging_freq': 5,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        62\n",
      "           1       0.98      1.00      0.99      3687\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.50      3749\n",
      "weighted avg       0.97      0.98      0.98      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00     300.0\n",
      "         1.0       0.00      1.00      0.00       0.0\n",
      "\n",
      "    accuracy                           1.00     300.0\n",
      "   macro avg       0.50      0.50      0.00     300.0\n",
      "weighted avg       1.00      0.00      0.00     300.0\n",
      "\n",
      "300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.61      0.04        62\n",
      "           1       0.99      0.51      0.68      3687\n",
      "\n",
      "    accuracy                           0.52      3749\n",
      "   macro avg       0.50      0.56      0.36      3749\n",
      "weighted avg       0.97      0.52      0.67      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.52      0.68       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.52       300\n",
      "   macro avg       0.50      0.76      0.34       300\n",
      "weighted avg       1.00      0.52      0.68       300\n",
      "\n",
      "300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      1.00      0.03        62\n",
      "           1       1.00      0.01      0.01      3687\n",
      "\n",
      "    accuracy                           0.02      3749\n",
      "   macro avg       0.51      0.50      0.02      3749\n",
      "weighted avg       0.98      0.02      0.01      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "performance_data = []\n",
    "for X_train_processed, y_train_processed, method_name in data_list:\n",
    "    lgb_model = lgb.LGBMClassifier(**params, verbose=-1)\n",
    "\n",
    "    lgb_model.fit(X_train_processed, y_train_processed)\n",
    "\n",
    "    print(len(negative_data))\n",
    "    y_pred = lgb_model.predict(X_test)\n",
    "    y_prob = lgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    negative_data_pred = lgb_model.predict(negative_data)\n",
    "    negative_accuracy = accuracy_score(negative_label_list, negative_data_pred)\n",
    "\n",
    "    print(\n",
    "        classification_report(negative_label_list,\n",
    "                              negative_data_pred,\n",
    "                              zero_division=1))\n",
    "\n",
    "    performance_data.append({\n",
    "        'Classification Method' : 'LightGBM',\n",
    "        'Data Process Method': method_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Negative Accuracy': negative_accuracy,\n",
    "    })\n",
    "    index += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Original Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.02      0.03        62\n",
      "           1       0.98      1.00      0.99      3687\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.52      0.51      0.51      3749\n",
      "weighted avg       0.97      0.98      0.97      3749\n",
      "\n",
      "Classification Report for Original Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.02      0.04       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.02       300\n",
      "   macro avg       0.50      0.51      0.02       300\n",
      "weighted avg       1.00      0.02      0.04       300\n",
      "\n",
      "Classification Report for Under-sampled Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.58      0.04        62\n",
      "           1       0.99      0.56      0.71      3687\n",
      "\n",
      "    accuracy                           0.56      3749\n",
      "   macro avg       0.50      0.57      0.38      3749\n",
      "weighted avg       0.97      0.56      0.70      3749\n",
      "\n",
      "Classification Report for Under-sampled Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.85      0.92       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.85       300\n",
      "   macro avg       0.50      0.92      0.46       300\n",
      "weighted avg       1.00      0.85      0.92       300\n",
      "\n",
      "Classification Report for SMOTE Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.90      0.03        62\n",
      "           1       0.98      0.09      0.17      3687\n",
      "\n",
      "    accuracy                           0.11      3749\n",
      "   macro avg       0.50      0.50      0.10      3749\n",
      "weighted avg       0.97      0.11      0.17      3749\n",
      "\n",
      "Classification Report for SMOTE Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       0.50      1.00      0.50       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for X_train_processed, y_train_processed, method_name in data_list:\n",
    "    rfc = RandomForestClassifier(n_estimators=1000, max_features=12)\n",
    "    rfc.fit(X_train_processed, y_train_processed)\n",
    "    predictions = rfc.predict(X_test)\n",
    "    print(f\"Classification Report for {method_name} on Test Data:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    negative_predictions = rfc.predict(negative_data)\n",
    "    print(f\"Classification Report for {method_name} on Negative Data:\")\n",
    "    print(\n",
    "        classification_report(negative_label_list,\n",
    "                              negative_predictions,\n",
    "                              zero_division=1))\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    performance_data.append({\n",
    "        'Classification Method': 'Random Forest',\n",
    "        'Data Process Method': method_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Negative Accuracy': negative_accuracy,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost for Desicion Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Original Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        62\n",
      "           1       0.98      1.00      0.99      3687\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.50      3749\n",
      "weighted avg       0.97      0.98      0.98      3749\n",
      "\n",
      "Classification Report for Original Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00     300.0\n",
      "         1.0       0.00      1.00      0.00       0.0\n",
      "\n",
      "    accuracy                           1.00     300.0\n",
      "   macro avg       0.50      0.50      0.00     300.0\n",
      "weighted avg       1.00      0.00      0.00     300.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Under-sampled Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.60      0.04        62\n",
      "           1       0.99      0.53      0.69      3687\n",
      "\n",
      "    accuracy                           0.53      3749\n",
      "   macro avg       0.50      0.56      0.37      3749\n",
      "weighted avg       0.97      0.53      0.68      3749\n",
      "\n",
      "Classification Report for Under-sampled Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.55      0.71       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.55       300\n",
      "   macro avg       0.50      0.77      0.35       300\n",
      "weighted avg       1.00      0.55      0.71       300\n",
      "\n",
      "Classification Report for SMOTE Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      1.00      0.03        62\n",
      "           1       1.00      0.00      0.00      3687\n",
      "\n",
      "    accuracy                           0.02      3749\n",
      "   macro avg       0.51      0.50      0.02      3749\n",
      "weighted avg       0.98      0.02      0.00      3749\n",
      "\n",
      "Classification Report for SMOTE Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for X_train_processed, y_train_processed, method_name in data_list:\n",
    "    # 使用决策树桩作为弱分类器，也可以选择其他弱分类器\n",
    "    base_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "    # 使用AdaBoost分类器\n",
    "    adaboost = AdaBoostClassifier(base_classifier,\n",
    "                                  n_estimators=1000,\n",
    "                                  algorithm='SAMME',\n",
    "                                  random_state=42)\n",
    "\n",
    "    # 训练模型\n",
    "    adaboost.fit(X_train_processed, y_train_processed)\n",
    "\n",
    "    # 在测试集上进行预测和评估\n",
    "    predictions_test = adaboost.predict(X_test)\n",
    "    print(f\"Classification Report for {method_name} on Test Data:\")\n",
    "    print(classification_report(y_test, predictions_test))\n",
    "\n",
    "    # 在负样本数据上进行预测和评估\n",
    "    predictions_negative = adaboost.predict(negative_data)\n",
    "    print(f\"Classification Report for {method_name} on Negative Data:\")\n",
    "    print(\n",
    "        classification_report(negative_label_list,\n",
    "                              predictions_negative,\n",
    "                              zero_division=1))\n",
    "    accuracy = accuracy_score(y_test, predictions_test)\n",
    "    precision = precision_score(y_test, predictions_test)\n",
    "    recall = recall_score(y_test, predictions_test)\n",
    "    f1 = f1_score(y_test, predictions_test)\n",
    "    performance_data.append({\n",
    "        'Classification Method': 'AdaBoost for Decision Tree',\n",
    "        'Data Process Method': method_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Negative Accuracy': negative_accuracy,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Original Data - SVM Classification Report on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        62\n",
      "           1       0.98      1.00      0.99      3687\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.50      3749\n",
      "weighted avg       0.97      0.98      0.98      3749\n",
      "\n",
      "Method: Original Data - SVM Classification Report on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "Method: Under-sampled Data - SVM Classification Report on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.53      0.03        62\n",
      "           1       0.98      0.50      0.67      3687\n",
      "\n",
      "    accuracy                           0.50      3749\n",
      "   macro avg       0.50      0.52      0.35      3749\n",
      "weighted avg       0.97      0.50      0.66      3749\n",
      "\n",
      "Method: Under-sampled Data - SVM Classification Report on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: SMOTE Data - SVM Classification Report on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.18      0.03        62\n",
      "           1       0.98      0.81      0.89      3687\n",
      "\n",
      "    accuracy                           0.80      3749\n",
      "   macro avg       0.50      0.49      0.46      3749\n",
      "weighted avg       0.97      0.80      0.87      3749\n",
      "\n",
      "Method: SMOTE Data - SVM Classification Report on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for X_train_processed, y_train_processed, method_name in data_list:\n",
    "   # 使用 SVM 替代 RandomForestClassifier\n",
    "   svm_model = SVC()\n",
    "   svm_model.fit(X_train_processed, y_train_processed)\n",
    "\n",
    "   # SVM 在测试集上的分类报告\n",
    "   predictions_svm_test = svm_model.predict(X_test)\n",
    "   print(f\"Method: {method_name} - SVM Classification Report on Test Data:\")\n",
    "   print(classification_report(y_test, predictions_svm_test))\n",
    "\n",
    "   # SVM 在负样本上的分类报告\n",
    "   predictions_svm_negative = svm_model.predict(negative_data)\n",
    "   print(\n",
    "      f\"Method: {method_name} - SVM Classification Report on Negative Data:\")\n",
    "   print(\n",
    "      classification_report(negative_label_list,\n",
    "                           predictions_negative,\n",
    "                           zero_division=1))\n",
    "   accuracy = accuracy_score(y_test, predictions_svm_test)\n",
    "   precision = precision_score(y_test, predictions_svm_test)\n",
    "   recall = recall_score(y_test, predictions_svm_test)\n",
    "   f1 = f1_score(y_test, predictions_svm_test)\n",
    "   performance_data.append({\n",
    "       'Classification Method': 'SVM',\n",
    "       'Data Process Method': method_name,\n",
    "       'Accuracy': accuracy,\n",
    "       'Precision': precision,\n",
    "       'Recall': recall,\n",
    "       'F1 Score': f1,\n",
    "       'Negative Accuracy': negative_accuracy,\n",
    "   })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# for X_train_processed, y_train_processed, method_name in data_list:\n",
    "#     # 使用支持向量机作为弱分类器\n",
    "#     base_classifier = SVC(kernel='linear', C=1.0)\n",
    "\n",
    "#     # 使用AdaBoost分类器\n",
    "#     adaboost = AdaBoostClassifier(base_classifier,\n",
    "#                                   n_estimators=1000,\n",
    "#                                   algorithm='SAMME',\n",
    "#                                   random_state=42)\n",
    "\n",
    "#     # 训练模型\n",
    "#     adaboost.fit(X_train_processed, y_train_processed)\n",
    "\n",
    "#     # 在测试集上进行预测和评估\n",
    "#     predictions_test = adaboost.predict(X_test)\n",
    "#     print(f\"Classification Report for {method_name} on Test Data:\")\n",
    "#     print(classification_report(y_test, predictions_test))\n",
    "\n",
    "#     # 在负样本数据上进行预测和评估\n",
    "#     predictions_negative = adaboost.predict(negative_data)\n",
    "#     print(f\"Classification Report for {method_name} on Negative Data:\")\n",
    "#     print(\n",
    "#         classification_report(negative_label_list,\n",
    "#                               predictions_negative,\n",
    "#                               zero_division=1))\n",
    "#     accuracy = accuracy_score(y_test, predictions_test)\n",
    "#     precision = precision_score(y_test, predictions_test)\n",
    "#     recall = recall_score(y_test, predictions_test)\n",
    "#     f1 = f1_score(y_test, predictions_test)\n",
    "#     performance_data.append({\n",
    "#         'Classification Method': 'AdaBoost for SVM',\n",
    "#         'Data Process Method': method_name,\n",
    "#         'Accuracy': accuracy,\n",
    "#         'Precision': precision,\n",
    "#         'Recall': recall,\n",
    "#         'F1 Score': f1,\n",
    "#         'Negative Accuracy': negative_accuracy,\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 0\n",
    "# for X_train_processed, y_train_processed, method_name in data_list:\n",
    "#     svm_model = SVC()\n",
    "#     train_feature = train_features[index]\n",
    "#     test_feature = test_features[index]\n",
    "#     svm_model.fit(train_feature, y_train_processed)\n",
    "#     predictions = svm_model.predict(test_feature)\n",
    "#     print(classification_report(y_test,predictions))\n",
    "#     predictions = svm_model.predict(negative_data_list[index])\n",
    "#    print(classification_report(negative_label_list, predictions_negative, zero_division=1))\n",
    "#     index = index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for the method: Original Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 99\n",
      "Training for the method: Under-sampled Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 99\n",
      "Training for the method: SMOTE Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "model_list = []\n",
    "for X_train_processed, _, method_name in data_list:\n",
    "   print(\"Training for the method: \" + method_name)\n",
    "   model = train_vae(X_train=X_train_processed,X_test=X_test, progress=False,num_epoch=100).eval()\n",
    "   model_list.append(model)\n",
    "\n",
    "total_list = [ t+ (data,)  for t, data in zip(data_list, model_list)]\n",
    "\n",
    "index = 0\n",
    "train_features = []\n",
    "test_features = []\n",
    "negative_data_list = []\n",
    "for X_train_processed, _, method_name, __ in total_list:\n",
    "    train_features.append(model_list[index].encoder(torch.Tensor(X_train_processed).to(device)).cpu().detach().numpy())\n",
    "    test_features.append(model_list[index].encoder(torch.Tensor(X_test).to(device)).detach().cpu().numpy())\n",
    "    negative_data_list.append(model_list[index].encoder(torch.Tensor(negative_data).to(device)).detach().cpu().numpy())\n",
    "    index+=1\n",
    "\n",
    "   \n",
    "# for X_train_processed, _, method_name, model in model_list:\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         encoded_data = model.encoder(torch.Tensor(X_train_processed).to(device))\n",
    "#         encoded_data = encoded_data.cpu().numpy()\n",
    "#         tsne = TSNE(n_components=2)\n",
    "#         reduced_data = tsne.fit_transform(encoded_data)\n",
    "\n",
    "# plt.scatter(reduced_data[:, 0], reduced_data[:, 1])\n",
    "# plt.title(\"VAE Visualization\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM for VAE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        62\n",
      "           1       0.98      1.00      0.99      3687\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.50      3749\n",
      "weighted avg       0.97      0.98      0.98      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00     300.0\n",
      "         1.0       0.00      1.00      0.00       0.0\n",
      "\n",
      "    accuracy                           1.00     300.0\n",
      "   macro avg       0.50      0.50      0.00     300.0\n",
      "weighted avg       1.00      0.00      0.00     300.0\n",
      "\n",
      "300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.50      0.03        62\n",
      "           1       0.98      0.48      0.65      3687\n",
      "\n",
      "    accuracy                           0.48      3749\n",
      "   macro avg       0.50      0.49      0.34      3749\n",
      "weighted avg       0.97      0.48      0.64      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.56      0.72       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.56       300\n",
      "   macro avg       0.50      0.78      0.36       300\n",
      "weighted avg       1.00      0.56      0.72       300\n",
      "\n",
      "300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.21      0.02        62\n",
      "           1       0.98      0.72      0.83      3687\n",
      "\n",
      "    accuracy                           0.71      3749\n",
      "   macro avg       0.50      0.47      0.43      3749\n",
      "weighted avg       0.97      0.71      0.82      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.25      0.40       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.25       300\n",
      "   macro avg       0.50      0.63      0.20       300\n",
      "weighted avg       1.00      0.25      0.40       300\n",
      "\n",
      "   Classification Method Data Process Method  Accuracy  Precision    Recall  \\\n",
      "0  LightGBM for VAE data       Original Data  0.983462   0.983462  1.000000   \n",
      "1  LightGBM for VAE data  Under-sampled Data  0.482795   0.982873  0.482506   \n",
      "2  LightGBM for VAE data          SMOTE Data  0.714591   0.981952  0.723081   \n",
      "\n",
      "   F1 Score  Negative Accuracy  \n",
      "0  0.991662           0.000000  \n",
      "1  0.647262           0.556667  \n",
      "2  0.832865           0.253333  \n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "performance_data = []\n",
    "data_df = pd.DataFrame(columns=['Method', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Negative Accuracy'])\n",
    "\n",
    "for X_train_processed, y_train_processed, method_name, _ in total_list:\n",
    "    lgb_model = lgb.LGBMClassifier(**params, verbose=-1)\n",
    "\n",
    "    lgb_model.fit(train_features[index], y_train_processed)\n",
    "\n",
    "    print(len(negative_data))\n",
    "    y_pred = lgb_model.predict(test_features[index])\n",
    "    y_prob = lgb_model.predict_proba(test_features[index])[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    negative_data_pred = lgb_model.predict(negative_data_list[index])\n",
    "    negative_accuracy = accuracy_score(negative_label_list, negative_data_pred)\n",
    "\n",
    "    print(\n",
    "        classification_report(negative_label_list,\n",
    "                              negative_data_pred,\n",
    "                              zero_division=1))\n",
    "\n",
    "    performance_data.append({\n",
    "        'Classification Method': 'LightGBM for VAE data',\n",
    "        'Data Process Method': method_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Negative Accuracy': negative_accuracy,\n",
    "    })\n",
    "    index += 1\n",
    "\n",
    "data_df = pd.DataFrame(performance_data)\n",
    "print(data_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM for VAE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        62\n",
      "           1       0.98      1.00      0.99      3687\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.50      3749\n",
      "weighted avg       0.97      0.98      0.98      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00     300.0\n",
      "         1.0       0.00      1.00      0.00       0.0\n",
      "\n",
      "    accuracy                           1.00     300.0\n",
      "   macro avg       0.50      0.50      0.00     300.0\n",
      "weighted avg       1.00      0.00      0.00     300.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.56      0.04        62\n",
      "           1       0.99      0.60      0.75      3687\n",
      "\n",
      "    accuracy                           0.60      3749\n",
      "   macro avg       0.51      0.58      0.40      3749\n",
      "weighted avg       0.97      0.60      0.74      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.54      0.70       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.54       300\n",
      "   macro avg       0.50      0.77      0.35       300\n",
      "weighted avg       1.00      0.54      0.70       300\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.29      0.03        62\n",
      "           1       0.98      0.74      0.84      3687\n",
      "\n",
      "    accuracy                           0.73      3749\n",
      "   macro avg       0.50      0.51      0.44      3749\n",
      "weighted avg       0.97      0.73      0.83      3749\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.26      0.42       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.26       300\n",
      "   macro avg       0.50      0.63      0.21       300\n",
      "weighted avg       1.00      0.26      0.42       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for X_train_processed, y_train_processed, method_name in data_list:\n",
    "    svm_model = SVC()\n",
    "    train_feature = train_features[index]\n",
    "    test_feature = test_features[index]\n",
    "    svm_model.fit(train_feature, y_train_processed)\n",
    "    predictions = svm_model.predict(test_feature)\n",
    "    print(classification_report(y_test, predictions))\n",
    "    negative_predictions= svm_model.predict(negative_data_list[index])\n",
    "    print(\n",
    "        classification_report(negative_label_list,\n",
    "                              negative_predictions,\n",
    "                              zero_division=1))\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    negative_accuracy = accuracy_score(negative_label_list, negative_predictions)\n",
    "    performance_data.append({\n",
    "        'Classification Method':\n",
    "        'SVM for VAE data',\n",
    "        'Data Process Method':\n",
    "        method_name,\n",
    "        'Accuracy':\n",
    "        accuracy,\n",
    "        'Precision':\n",
    "        precision,\n",
    "        'Recall':\n",
    "        recall,\n",
    "        'F1 Score':\n",
    "        f1,\n",
    "        'Negative Accuracy':\n",
    "        negative_accuracy,\n",
    "    })\n",
    "    index = index + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost for Desicion Tree for VAE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Original Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        62\n",
      "           1       0.98      1.00      0.99      3687\n",
      "\n",
      "    accuracy                           0.98      3749\n",
      "   macro avg       0.49      0.50      0.50      3749\n",
      "weighted avg       0.97      0.98      0.98      3749\n",
      "\n",
      "Classification Report for Original Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.01       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.00       300\n",
      "   macro avg       0.50      0.50      0.00       300\n",
      "weighted avg       1.00      0.00      0.01       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\Docu\\DateMining\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Under-sampled Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.60      0.04        62\n",
      "           1       0.99      0.52      0.68      3687\n",
      "\n",
      "    accuracy                           0.52      3749\n",
      "   macro avg       0.50      0.56      0.36      3749\n",
      "weighted avg       0.97      0.52      0.67      3749\n",
      "\n",
      "Classification Report for Under-sampled Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.59      0.74       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.59       300\n",
      "   macro avg       0.50      0.79      0.37       300\n",
      "weighted avg       1.00      0.59      0.74       300\n",
      "\n",
      "Classification Report for SMOTE Data on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.37      0.03        62\n",
      "           1       0.98      0.62      0.76      3687\n",
      "\n",
      "    accuracy                           0.62      3749\n",
      "   macro avg       0.50      0.50      0.40      3749\n",
      "weighted avg       0.97      0.62      0.75      3749\n",
      "\n",
      "Classification Report for SMOTE Data on Negative Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.29      0.45       300\n",
      "         1.0       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.29       300\n",
      "   macro avg       0.50      0.65      0.23       300\n",
      "weighted avg       1.00      0.29      0.45       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for X_train_processed, y_train_processed, method_name in data_list:\n",
    "\n",
    "    train_feature = train_features[index]\n",
    "    test_feature = test_features[index]\n",
    "    # 使用决策树桩作为弱分类器，也可以选择其他弱分类器\n",
    "    base_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "    # 使用AdaBoost分类器\n",
    "    adaboost = AdaBoostClassifier(base_classifier,\n",
    "                                  n_estimators=1000,\n",
    "                                  algorithm='SAMME',\n",
    "                                  random_state=42)\n",
    "\n",
    "    # 训练模型\n",
    "    adaboost.fit(train_feature, y_train_processed)\n",
    "\n",
    "    # 在测试集上进行预测和评估\n",
    "    predictions_test = adaboost.predict(test_feature)\n",
    "    print(f\"Classification Report for {method_name} on Test Data:\")\n",
    "    print(classification_report(y_test, predictions_test))\n",
    "\n",
    "    # 在负样本数据上进行预测和评估\n",
    "    predictions_negative = adaboost.predict(negative_data_list[index])\n",
    "    print(f\"Classification Report for {method_name} on Negative Data:\")\n",
    "    print(\n",
    "        classification_report(negative_label_list,\n",
    "                              predictions_negative,\n",
    "                              zero_division=1))\n",
    "    accuracy = accuracy_score(y_test, predictions_test)\n",
    "    precision = precision_score(y_test, predictions_test)\n",
    "    recall = recall_score(y_test, predictions_test)\n",
    "    f1 = f1_score(y_test, predictions_test)\n",
    "    negative_accuracy = accuracy_score(negative_label_list, predictions_negative)\n",
    "    performance_data.append({\n",
    "        'Classification Method': 'AdaBoost for Decision Tree',\n",
    "        'Data Process Method': method_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Negative Accuracy': negative_accuracy,\n",
    "    })\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best Accuracy Classification Method: LightGBM for VAE data\n",
      "Best Accuracy Data Process Method: Original Data\n",
      "Best Accuracy Value: 0.9834622566017605\n",
      "best Accuracy Classification Method: SVM for VAE data\n",
      "Best Precision Data Process Method: Under-sampled Data\n",
      "Best Precision Value: 0.9879732739420936\n",
      "best Accuracy Classification Method: LightGBM for VAE data\n",
      "Best Recall Data Process Method: Original Data\n",
      "Best Recall Value: 1.0\n",
      "best Accuracy Classification Method: LightGBM for VAE data\n",
      "Best F1 Score Data Process Method: Original Data\n",
      "Best F1 Score Value: 0.9916621839698763\n",
      "best Accuracy Classification Method: AdaBoost for Decision Tree\n",
      "Best Negative Accuracy Data Process Method: Under-sampled Data\n",
      "Best Negative Accuracy Value: 0.5866666666666667\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.DataFrame(performance_data)\n",
    "# 找到最佳性能数据的行\n",
    "best_accuracy_row = data_df[data_df['Accuracy'] == data_df['Accuracy'].max()]\n",
    "best_precision_row = data_df[data_df['Precision'] == data_df['Precision'].max()]\n",
    "best_recall_row = data_df[data_df['Recall'] == data_df['Recall'].max()]\n",
    "best_f1_score_row = data_df[data_df['F1 Score'] == data_df['F1 Score'].max()]\n",
    "best_negative_accuracy_row = data_df[data_df['Negative Accuracy'] == data_df['Negative Accuracy'].max()]\n",
    "\n",
    "# 输出最佳性能数据\n",
    "print(\"best Accuracy Classification Method:\", best_accuracy_row['Classification Method'].values[0])\n",
    "print(\"Best Accuracy Data Process Method:\", best_accuracy_row['Data Process Method'].values[0])\n",
    "print(\"Best Accuracy Value:\", best_accuracy_row['Accuracy'].values[0])\n",
    "\n",
    "print(\"best Accuracy Classification Method:\", best_precision_row['Classification Method'].values[0])\n",
    "print(\"Best Precision Data Process Method:\", best_precision_row['Data Process Method'].values[0])\n",
    "print(\"Best Precision Value:\", best_precision_row['Precision'].values[0])\n",
    "\n",
    "print(\"best Accuracy Classification Method:\", best_recall_row['Classification Method'].values[0])\n",
    "print(\"Best Recall Data Process Method:\", best_recall_row['Data Process Method'].values[0])\n",
    "print(\"Best Recall Value:\", best_recall_row['Recall'].values[0])\n",
    "\n",
    "print(\"best Accuracy Classification Method:\", best_f1_score_row['Classification Method'].values[0])\n",
    "print(\"Best F1 Score Data Process Method:\", best_f1_score_row['Data Process Method'].values[0])\n",
    "print(\"Best F1 Score Value:\", best_f1_score_row['F1 Score'].values[0])\n",
    "\n",
    "\n",
    "print(\"best Accuracy Classification Method:\", best_negative_accuracy_row['Classification Method'].values[0])\n",
    "print(\"Best Negative Accuracy Data Process Method:\", best_negative_accuracy_row['Data Process Method'].values[0])\n",
    "print(\"Best Negative Accuracy Value:\", best_negative_accuracy_row['Negative Accuracy'].values[0])\n",
    "data_df.to_csv('performance_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
